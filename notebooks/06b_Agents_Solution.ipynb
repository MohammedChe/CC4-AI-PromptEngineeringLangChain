{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "urHo-WgXaBU0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwzkpsd8HfUp"
   },
   "source": [
    "# ü§ñ Agents in LangChain\n",
    "\n",
    "**Agents** are the driving force in LangChain, smart systems that use language models to work with other digital tools, perfect for tasks like Q&A, API interactions, and more.\n",
    "\n",
    "### üÜö Agents vs. Chains\n",
    "\n",
    "- **Agents** dynamically decide on actions using language models.\n",
    "- **Chains** have a predetermined sequence of actions.\n",
    "\n",
    "Agents are about smart decision-making and interacting with the digital environment, while chains are about a pre-set flow of information.\n",
    "\n",
    "### üõ†Ô∏è Tools and Toolkits\n",
    "\n",
    "- **Tools** are like an agent's skills, specific to tasks like data retrieval.\n",
    "- **Toolkits** bundle these skills for more complex tasks.\n",
    "\n",
    "### üß† The Role of Memory\n",
    "\n",
    "- Memory gives agents the ability to remember and use past interactions, making them smarter over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7j06PACDKwOI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cherbatjim\\Desktop\\AI\\CC4-AI-PromptEngineeringLangChain\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
      "c:\\Users\\cherbatjim\\Desktop\\AI\\CC4-AI-PromptEngineeringLangChain\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "open_ai_model = \"gpt-5-nano-2025-08-07\" \n",
    "# instantiate the llm\n",
    "llm = ChatOpenAI(model=open_ai_model,temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_1maSKXMqr2"
   },
   "source": [
    "# Giving the Agent Tools\n",
    "\n",
    "\n",
    " - üõ†Ô∏è üîß Tools are integrated into agents either all at once during setup  or individually as needed .\n",
    "\n",
    " - üß∞ Opt for LangChain's ready-made tools or craft your own custom tools to meet your unique needs.\n",
    "\n",
    "You can find the available native tools [here](https://docs.langchain.com/oss/python/integrations/tools)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K4io9CnjMn87"
   },
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# DuckDuckGo search\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "# Wikipedia\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=None))\n",
    "\n",
    "# equip it with some tools\n",
    "tools = [search, wikipedia]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rApQqQLgM6De"
   },
   "source": [
    "# Create the agent\n",
    "\n",
    "**Setting Up an Agent:**\n",
    "\n",
    "The model is the reasoning engine of your agent. It can be specified in multiple ways, supporting both static and dynamic model selection.\n",
    "\n",
    "1. **Static Model** üõ†Ô∏è: Static models are configured once when creating the agent and remain unchanged throughout execution. This is the most common and straightforward approach.\n",
    "\n",
    "2. **Dynamic model** üöÄ: Dynamic models are selected at runtime based on the current state and context. This enables sophisticated routing logic and cost optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3yw4Ww6ZNDtA"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Who is the current Chief AI Scientist at Meta AI? When was he born? Where was he born? What's the current temperature there?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "XgIQgekbMj-I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"\\nWho is the current Chief AI Scientist at Meta AI? When was he born? Where was he born? What's the current temperature there?\\n\", additional_kwargs={}, response_metadata={}, id='d36b6662-0ee8-47fa-baee-ca6a10e49597'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 675, 'prompt_tokens': 257, 'total_tokens': 932, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 640, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfOCRARMR3IAT421KRh5BN8ArSN7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--988583ec-600f-450d-94b6-fc48fa63c913-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Who is the Chief AI Scientist at Meta AI'}, 'id': 'call_c3sWudF9zCtleiFkUZNFEjKY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 257, 'output_tokens': 675, 'total_tokens': 932, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 640}}), ToolMessage(content='He is the Silver Professor of the Courant Institute of Mathematical Sciences at New York University and Vice President, Chief AI Scientist at Meta .[3][4]. He is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs).[5]... Nick Clegg and Yann LeCun, president of Global Affairs and chief AI scientist at Meta , respectively, shared their views on the matter in a meeting with journalists from five international media outlets, including EL PA√çS. Yann LeCun, the chief AI scientist at Meta , has warned that most robotics companies do not know how to develop the intelligence required to make humanoid robots useful and are focused, instead, on building the hardware. Who is Yann LeCun? At Nasscom AI Confluence in Delhi, Yann LeCun, Chief AI Scientist at Meta , highlighted some of the remarkable ways AI is transforming key sectors such as healthcare and transportation. Yann LeCun, a famous computer scientist , who is a professor at New York University, and the chief AI scientist at Meta , says we overestimate the pros and cons of artificial intelligence ( AI ).', name='duckduckgo_search', id='a23703db-b6c9-4616-8f41-d94c863c11f1', tool_call_id='call_c3sWudF9zCtleiFkUZNFEjKY'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 765, 'prompt_tokens': 530, 'total_tokens': 1295, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 704, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfOJ3K9BGrkfNEzxOurI6aSQ8odV', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--01421998-f3d9-4a2a-878c-04576f93d261-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Yann LeCun'}, 'id': 'call_xswFDhGmjp4XfDcsHa0H5P8H', 'type': 'tool_call'}, {'name': 'duckduckgo_search', 'args': {'query': 'Paris current temperature'}, 'id': 'call_Vk21X5ChJN6d7esrUp0BK4mT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 530, 'output_tokens': 765, 'total_tokens': 1295, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 704}}), ToolMessage(content='Page: Yann LeCun\\nSummary: Yann Andr√© Le Cun ( l…ô-KUN, French: [l…ôk≈ìÃÉ]; usually spelled LeCun; born 8 July 1960) is a French-American computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics and computational neuroscience. He is the Jacob T. Schwartz Professor of Computer Science at the Courant Institute of Mathematical Sciences at New York University and Chief Artificial Intelligence (AI) Scientist at Meta.\\nHe is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs). He is also one of the main creators of the DjVu image compression technology, alongside L√©on Bottou and Patrick Haffner. He co-developed the Lush programming language with L√©on Bottou.\\nIn 2018, LeCun, Yoshua Bengio, and Geoffrey Hinton, received the Turing Award for their work on deep learning. The three are sometimes referred to as the \"Godfathers of AI\" and \"Godfathers of Deep Learning\".\\n\\nPage: Geoffrey Hinton\\nSummary: Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist, cognitive scientist, and cognitive psychologist known for his work on artificial neural networks, which earned him the title \"the Godfather of AI\".\\nHinton is University Professor Emeritus at the University of Toronto. From 2013 to 2023, he divided his time working for Google Brain and the University of Toronto before publicly announcing his departure from Google in May 2023, citing concerns about the many risks of artificial intelligence (AI) technology. In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.\\nWith David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 that popularised the backpropagation algorithm for training multi-layer neural networks, although they were not the first to propose the approach. Hinton is viewed as a leading figure in the deep learning community. The image-recognition milestone of the AlexNet designed in collaboration with his students Alex Krizhevsky and Ilya Sutskever for the ImageNet challenge 2012 was a breakthrough in the field of computer vision.\\nHinton received the 2018 Turing Award, together with Yoshua Bengio and Yann LeCun for their work on deep learning. They are sometimes referred to as the \"Godfathers of Deep Learning\" and have continued to give public talks together. He was also awarded, along with John Hopfield, the 2024 Nobel Prize in Physics for \"foundational discoveries and inventions that enable machine learning with artificial neural networks\".\\nIn May 2023, Hinton announced his resignation from Google to be able to \"freely speak out about the risks of A.I.\" He has voiced concerns about deliberate misuse by malicious actors, technological unemployment, and existential risk from artificial general intelligence. He noted that establishing safety guidelines will require cooperation among those competing in use of AI in order to avoid the worst outcomes. After receiving the Nobel Prize, he called for urgent research into AI safety to figure out how to control AI systems smarter than humans.\\n\\nPage: LeNet\\nSummary: LeNet is a series of convolutional neural network architectures created by a research group in AT&T Bell Laboratories during the 1988 to 1998 period, centered around Yann LeCun. They were designed for reading small grayscale images of handwritten digits and letters, and were used in ATM for reading cheques.\\nConvolutional neural networks are a kind of feed-forward neural network whose artificial neurons can respond to a part of the surrounding cells in the coverage range and perform well in large-scale image processing. LeNet-5 was one of the earliest convolutional neural networks and was historically important during the development of deep learning.\\nIn general, when LeNet is referred to without a number, it refers to the 1998 version, the most well-known version. It is also sometimes called LeNet-5.\\n\\n', name='wikipedia', id='60d017c1-f1ba-44c4-8085-790d6e416343', tool_call_id='call_xswFDhGmjp4XfDcsHa0H5P8H'), ToolMessage(content='Currently, in Paris , golden sunlight is making everything look vibrant and warm . ... The temperature will be between the highest temperature of 80.6 ... The current temperature is near the lowest anticipated 9¬∞C for today. ... What will be the maximum temperature today in Paris ? The maximum air temperature in Paris for this day for the last 76 years of observations is +17.6¬∞C, recorded in 1995. The coldest months in Paris are December , January , and February , with temperatures usually reaching an average low of 3 ¬∞ C (37 ¬∞ F). Currently, in Paris , a dense layer of clouds is spreading across the sky, making it predominantly cloudy . ... The current temperature is a few ...', name='duckduckgo_search', id='31cb8f9d-eed7-410f-bfbd-123900c8d37a', tool_call_id='call_Vk21X5ChJN6d7esrUp0BK4mT'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 835, 'prompt_tokens': 1628, 'total_tokens': 2463, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 768, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfORiDbAB27S6OMx0cViuLrXCFDO', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--1410836a-3845-47aa-9c57-3786a09a71d7-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Yann LeCun'}, 'id': 'call_LLKYB7BlTdDN55Rvha6UHXtZ', 'type': 'tool_call'}, {'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature'}, 'id': 'call_z8iRw6dDyqtyvNKdAm9ZIr43', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1628, 'output_tokens': 835, 'total_tokens': 2463, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 768}}), ToolMessage(content='Page: Yann LeCun\\nSummary: Yann Andr√© Le Cun ( l…ô-KUN, French: [l…ôk≈ìÃÉ]; usually spelled LeCun; born 8 July 1960) is a French-American computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics and computational neuroscience. He is the Jacob T. Schwartz Professor of Computer Science at the Courant Institute of Mathematical Sciences at New York University and Chief Artificial Intelligence (AI) Scientist at Meta.\\nHe is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs). He is also one of the main creators of the DjVu image compression technology, alongside L√©on Bottou and Patrick Haffner. He co-developed the Lush programming language with L√©on Bottou.\\nIn 2018, LeCun, Yoshua Bengio, and Geoffrey Hinton, received the Turing Award for their work on deep learning. The three are sometimes referred to as the \"Godfathers of AI\" and \"Godfathers of Deep Learning\".\\n\\nPage: Geoffrey Hinton\\nSummary: Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist, cognitive scientist, and cognitive psychologist known for his work on artificial neural networks, which earned him the title \"the Godfather of AI\".\\nHinton is University Professor Emeritus at the University of Toronto. From 2013 to 2023, he divided his time working for Google Brain and the University of Toronto before publicly announcing his departure from Google in May 2023, citing concerns about the many risks of artificial intelligence (AI) technology. In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.\\nWith David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 that popularised the backpropagation algorithm for training multi-layer neural networks, although they were not the first to propose the approach. Hinton is viewed as a leading figure in the deep learning community. The image-recognition milestone of the AlexNet designed in collaboration with his students Alex Krizhevsky and Ilya Sutskever for the ImageNet challenge 2012 was a breakthrough in the field of computer vision.\\nHinton received the 2018 Turing Award, together with Yoshua Bengio and Yann LeCun for their work on deep learning. They are sometimes referred to as the \"Godfathers of Deep Learning\" and have continued to give public talks together. He was also awarded, along with John Hopfield, the 2024 Nobel Prize in Physics for \"foundational discoveries and inventions that enable machine learning with artificial neural networks\".\\nIn May 2023, Hinton announced his resignation from Google to be able to \"freely speak out about the risks of A.I.\" He has voiced concerns about deliberate misuse by malicious actors, technological unemployment, and existential risk from artificial general intelligence. He noted that establishing safety guidelines will require cooperation among those competing in use of AI in order to avoid the worst outcomes. After receiving the Nobel Prize, he called for urgent research into AI safety to figure out how to control AI systems smarter than humans.\\n\\nPage: LeNet\\nSummary: LeNet is a series of convolutional neural network architectures created by a research group in AT&T Bell Laboratories during the 1988 to 1998 period, centered around Yann LeCun. They were designed for reading small grayscale images of handwritten digits and letters, and were used in ATM for reading cheques.\\nConvolutional neural networks are a kind of feed-forward neural network whose artificial neurons can respond to a part of the surrounding cells in the coverage range and perform well in large-scale image processing. LeNet-5 was one of the earliest convolutional neural networks and was historically important during the development of deep learning.\\nIn general, when LeNet is referred to without a number, it refers to the 1998 version, the most well-known version. It is also sometimes called LeNet-5.\\n\\n', name='wikipedia', id='23bea5d4-d78a-45e6-a405-c6e815193094', tool_call_id='call_LLKYB7BlTdDN55Rvha6UHXtZ'), ToolMessage(content='The highest temperature ever recorded in Villaines- sous -Bois was 41.6 ¬∞C (106.9 ¬∞F) on 25 July 2019; the coldest temperature ever recorded was ... The highest temperature ever recorded in Jagny- sous -Bois was 40.4 ¬∞C (104.7 ¬∞F) on 25 July 2019; the coldest temperature ever recorded was ‚àí19.0 ... ... Aulnay- sous -Bois ... Clichy- sous -Bois ... Fontenay- sous -Bois The temperature is forecasted to vary between a maximum of a hot ... The current temperature is nearly at the maximum of today s anticipated 32¬∞C. Currently, another day of fair weather brings comfortable and sunny conditions. ... The current temperature is a few degrees off the minimum of 13¬∞C.', name='duckduckgo_search', id='803364bc-b4c0-489e-af37-37c42f4114b2', tool_call_id='call_z8iRw6dDyqtyvNKdAm9ZIr43'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 708, 'prompt_tokens': 2774, 'total_tokens': 3482, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 640, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfOaWUHS9d3GLnr4uQgBhxOXRj1s', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--a81c4466-ebbc-4a6f-8e8a-58f67a5f4508-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Yann LeCun birthplace'}, 'id': 'call_lVVv2Ul92wmEYOjA7O5siFPG', 'type': 'tool_call'}, {'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature'}, 'id': 'call_GyEM8On66NPbKFhSaGPChNfl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2774, 'output_tokens': 708, 'total_tokens': 3482, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 640}}), ToolMessage(content=\"Page: Peter Higgs\\nSummary: Peter Ware Higgs (29 May 1929 ‚Äì 8 April 2024) was a British theoretical physicist, professor at the University of Edinburgh, and Nobel laureate in Physics for his work on the mass of subatomic particles.\\nIn 1964, Higgs was the single author of one of the three milestone papers published in Physical Review Letters (PRL) that proposed that spontaneous symmetry breaking in electroweak theory could explain the origin of mass of elementary particles in general and of the W and Z bosons in particular. This Higgs mechanism predicted the existence of a new particle, the Higgs boson, the detection of which became one of the great goals of physics. In 2012, CERN announced the discovery of the Higgs boson at the Large Hadron Collider. The Higgs mechanism is generally accepted as an important ingredient in the Standard Model of particle physics, without which certain particles would have no mass.\\nFor this work, Higgs received the Nobel Prize in Physics, which he shared with Fran√ßois Englert in 2013.\\n\\n\\n\\nPage: CERN\\nSummary: The European Organization for Nuclear Research, known as CERN (; French pronunciation: [s…õ Ån]; Organisation europ√©enne pour la recherche nucl√©aire), is an intergovernmental organization that operates the largest particle physics laboratory in the world. Established in 1954, it is based in Meyrin, a western suburb of Geneva, on the France‚ÄìSwitzerland border. It comprises 24 member states. Israel, admitted in 2013, is the only full member geographically out of Europe. CERN is an official United Nations General Assembly observer.\\nThe acronym CERN is also used to refer to the laboratory; in 2024, it had 2704 scientific, technical, and administrative staff members, and hosted about 12406 users from institutions in more than 80 countries. In 2016, CERN generated 49 petabytes of data.\\nCERN's main function is to provide the particle accelerators and other infrastructure needed for high-energy physics research ‚Äì consequently, numerous experiments have been constructed at CERN through international collaborations. CERN is the site of the Large Hadron Collider (LHC), the world's largest and highest-energy particle collider. The main site at Meyrin hosts a large computing facility, which is primarily used to store and analyze data from experiments, as well as simulate events. As researchers require remote access to these facilities, the lab has historically been a major wide area network hub. CERN is also the birthplace of the World Wide Web.\", name='wikipedia', id='ced3662b-e875-4117-a8ba-1dfa0478f0c3', tool_call_id='call_lVVv2Ul92wmEYOjA7O5siFPG'), ToolMessage(content=\"Soisy - sous - Montmorency - La rue de Montmorency vers 1900. La loi Loucheur en 1921 provoque une nouvelle vague de constructions qui feront cro√Ætre la population jusqu'√† 7 000 habitants en 1954 et 13 000 en 1964. The highest temperature ever recorded in Villaines- sous -Bois was 41.6 ¬∞C (106.9 ¬∞F) on 25 July 2019; the coldest temperature ever recorded was ... The highest temperature ever recorded in Jagny- sous -Bois was 40.4 ¬∞C (104.7 ¬∞F) on 25 July 2019; the coldest temperature ever recorded was ‚àí19.0 ... The forecast for Soisy - sous - Montmorency on June 6 is partly cloudy and warm. The temperature will vary from 16 to 22¬∞ during the day and around 16¬∞ during the night. Expected wind conditions are pleasant with a steady gentle breeze of 15 km/h and gusts of 45 km/h. Soisy - sous - Montmorency Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Soisy - sous - Montmorency area.\", name='duckduckgo_search', id='57f48e2f-3f50-4adf-af42-b624b89e76d9', tool_call_id='call_GyEM8On66NPbKFhSaGPChNfl'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 547, 'prompt_tokens': 3700, 'total_tokens': 4247, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2560}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfOhL5yJQq1LSSgIkEpnRYk4WscA', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--34017b84-5e0d-4553-8669-aae73519f0f3-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature'}, 'id': 'call_BgRraWd3OXVEDrwkOVmS20yQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3700, 'output_tokens': 547, 'total_tokens': 4247, 'input_token_details': {'audio': 0, 'cache_read': 2560}, 'output_token_details': {'audio': 0, 'reasoning': 512}}), ToolMessage(content=\"April 27, 2025 - Soisy-sous-Montmorency est desservie par la gare du Champ de courses d'Enghien, sur le r√©seau Transilien Paris-Nord, branches Paris-Nord ‚Äî Pontoise/Persan-Beaumont. La gare est desservie √† raison d'un train omnibus tous les 15 minutes en heures creuses et √† la m√™me fr√©quence en heures de pointe, les trains devenant en revanche semi-directs. October 10, 2025 - Premi√®re semaine (jusqu'au vendredi 17 octobre) : M√©t√©ocity pr√©voit entre 10¬∞C et 18¬∞C √† Soisy-sous-Montmorency. La temp√©rature moyenne sera en hausse de 1¬∞C environ par rapport √† √† celle d'aujourd'hui, vendredi 10 octobre. September 14, 2025 - The forecast for Soisy-sous-Montmorency today is mostly cloudy and warm. The temperature will vary from 54 to 66¬∞ during the day and 54 to 55¬∞ during the night . A consistent gentle breeze of 10 mph and gusts of up to 26 mph are anticipated. August 31, 2025 - Montmorency (2km) Saint-Gratien (2km) Domont (5km) Saint-Brice-sous-For√™t (5km) Montmagny (4km) Villetaneuse (5km) September 12, 2025 - Analyze the Soisy-sous-Montmorency centered high definition weather maps with hourly weather forecasts for precipitation, cloud cover, wind animation, temperature, atmospheric pressure and air quality index.\", name='duckduckgo_search', id='f33c1e8f-3c0b-453c-9ccd-db8010e6f849', tool_call_id='call_BgRraWd3OXVEDrwkOVmS20yQ'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 548, 'prompt_tokens': 4079, 'total_tokens': 4627, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 3584}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfOndtgfAFUa1CqZeBB1HKdp2w1y', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--c7597e73-d9de-4b9a-8749-e4e8e9428026-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature now'}, 'id': 'call_jVhg3YdDrGsY5UaHfIra1n0R', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4079, 'output_tokens': 548, 'total_tokens': 4627, 'input_token_details': {'audio': 0, 'cache_read': 3584}, 'output_token_details': {'audio': 0, 'reasoning': 512}}), ToolMessage(content='Soisy - sous - Montmorency , France - Current temperature and weather conditions. Detailed hourly weather forecast for today - including weather conditions, temperature , pressure, humidity, precipitation, dewpoint, wind, visibility, and UV index data. The current Soisy - sous - Montmorency weather right now according to the weather station. Accurate Soisy - sous - Montmorency weather today, forecast for sun, rain, wind and temperature . Soisy - sous - Montmorency Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Soisy - sous - Montmorency area. Soisy - sous - Montmorency - Weather forecast from Theweather.com. Weather conditions with updates on temperature , humidity, wind speed, snow, pressure, etc. for Soisy - sous - Montmorency , Val-d¬¥Oise.', name='duckduckgo_search', id='7ccc13e3-3f96-4a58-a0cc-1ec329008472', tool_call_id='call_jVhg3YdDrGsY5UaHfIra1n0R'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1029, 'prompt_tokens': 4303, 'total_tokens': 5332, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 960, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 3840}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfOrsM4cPzrHctBslYzxj1J5vrT2', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--080774e4-e0c3-4012-8da4-a8433d2c92df-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Yann LeCun birthplace'}, 'id': 'call_fuMq6tK1MfAX10f9UeYxHt53', 'type': 'tool_call'}, {'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature'}, 'id': 'call_ZBztC15TW0pkZ8FdJ6MOmI28', 'type': 'tool_call'}], usage_metadata={'input_tokens': 4303, 'output_tokens': 1029, 'total_tokens': 5332, 'input_token_details': {'audio': 0, 'cache_read': 3840}, 'output_token_details': {'audio': 0, 'reasoning': 960}}), ToolMessage(content=\"Page: Peter Higgs\\nSummary: Peter Ware Higgs (29 May 1929 ‚Äì 8 April 2024) was a British theoretical physicist, professor at the University of Edinburgh, and Nobel laureate in Physics for his work on the mass of subatomic particles.\\nIn 1964, Higgs was the single author of one of the three milestone papers published in Physical Review Letters (PRL) that proposed that spontaneous symmetry breaking in electroweak theory could explain the origin of mass of elementary particles in general and of the W and Z bosons in particular. This Higgs mechanism predicted the existence of a new particle, the Higgs boson, the detection of which became one of the great goals of physics. In 2012, CERN announced the discovery of the Higgs boson at the Large Hadron Collider. The Higgs mechanism is generally accepted as an important ingredient in the Standard Model of particle physics, without which certain particles would have no mass.\\nFor this work, Higgs received the Nobel Prize in Physics, which he shared with Fran√ßois Englert in 2013.\\n\\n\\n\\nPage: CERN\\nSummary: The European Organization for Nuclear Research, known as CERN (; French pronunciation: [s…õ Ån]; Organisation europ√©enne pour la recherche nucl√©aire), is an intergovernmental organization that operates the largest particle physics laboratory in the world. Established in 1954, it is based in Meyrin, a western suburb of Geneva, on the France‚ÄìSwitzerland border. It comprises 24 member states. Israel, admitted in 2013, is the only full member geographically out of Europe. CERN is an official United Nations General Assembly observer.\\nThe acronym CERN is also used to refer to the laboratory; in 2024, it had 2704 scientific, technical, and administrative staff members, and hosted about 12406 users from institutions in more than 80 countries. In 2016, CERN generated 49 petabytes of data.\\nCERN's main function is to provide the particle accelerators and other infrastructure needed for high-energy physics research ‚Äì consequently, numerous experiments have been constructed at CERN through international collaborations. CERN is the site of the Large Hadron Collider (LHC), the world's largest and highest-energy particle collider. The main site at Meyrin hosts a large computing facility, which is primarily used to store and analyze data from experiments, as well as simulate events. As researchers require remote access to these facilities, the lab has historically been a major wide area network hub. CERN is also the birthplace of the World Wide Web.\\n\\n\", name='wikipedia', id='fba56418-923f-4043-8148-85507e340969', tool_call_id='call_fuMq6tK1MfAX10f9UeYxHt53'), ToolMessage(content='The highest temperature ever recorded in Villaines- sous -Bois was 41.6 ¬∞C (106.9 ¬∞F) on 25 July 2019; the coldest temperature ever recorded was ... The highest temperature ever recorded in Jagny- sous -Bois was 40.4 ¬∞C (104.7 ¬∞F) on 25 July 2019; the coldest temperature ever recorded was ‚àí19.0 ... ... Aulnay- sous -Bois ... Clichy- sous -Bois ... Fontenay- sous -Bois The temperature is forecasted to vary between a maximum of a hot ... The current temperature is nearly at the maximum of today s anticipated 32¬∞C. Currently, another day of fair weather brings comfortable and sunny conditions. ... The current temperature is a few degrees off the minimum of 13¬∞C.', name='duckduckgo_search', id='1c19e9fc-3732-419a-86d1-cb79d524e83a', tool_call_id='call_ZBztC15TW0pkZ8FdJ6MOmI28'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 964, 'prompt_tokens': 5140, 'total_tokens': 6104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4096}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfP2QQp0sf8seq5HbWzsp6sM9dqa', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f885bce5-833d-4442-91ed-ae4bc31a12ce-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Yann LeCun'}, 'id': 'call_16AakoNXIesV3Vqv2cIDMKNC', 'type': 'tool_call'}, {'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature'}, 'id': 'call_Zkjs48z1DVnXBEcCrlqNW8XU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 5140, 'output_tokens': 964, 'total_tokens': 6104, 'input_token_details': {'audio': 0, 'cache_read': 4096}, 'output_token_details': {'audio': 0, 'reasoning': 896}}), ToolMessage(content='Page: Yann LeCun\\nSummary: Yann Andr√© Le Cun ( l…ô-KUN, French: [l…ôk≈ìÃÉ]; usually spelled LeCun; born 8 July 1960) is a French-American computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics and computational neuroscience. He is the Jacob T. Schwartz Professor of Computer Science at the Courant Institute of Mathematical Sciences at New York University and Chief Artificial Intelligence (AI) Scientist at Meta.\\nHe is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs). He is also one of the main creators of the DjVu image compression technology, alongside L√©on Bottou and Patrick Haffner. He co-developed the Lush programming language with L√©on Bottou.\\nIn 2018, LeCun, Yoshua Bengio, and Geoffrey Hinton, received the Turing Award for their work on deep learning. The three are sometimes referred to as the \"Godfathers of AI\" and \"Godfathers of Deep Learning\".\\n\\nPage: Geoffrey Hinton\\nSummary: Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist, cognitive scientist, and cognitive psychologist known for his work on artificial neural networks, which earned him the title \"the Godfather of AI\".\\nHinton is University Professor Emeritus at the University of Toronto. From 2013 to 2023, he divided his time working for Google Brain and the University of Toronto before publicly announcing his departure from Google in May 2023, citing concerns about the many risks of artificial intelligence (AI) technology. In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.\\nWith David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 that popularised the backpropagation algorithm for training multi-layer neural networks, although they were not the first to propose the approach. Hinton is viewed as a leading figure in the deep learning community. The image-recognition milestone of the AlexNet designed in collaboration with his students Alex Krizhevsky and Ilya Sutskever for the ImageNet challenge 2012 was a breakthrough in the field of computer vision.\\nHinton received the 2018 Turing Award, together with Yoshua Bengio and Yann LeCun for their work on deep learning. They are sometimes referred to as the \"Godfathers of Deep Learning\" and have continued to give public talks together. He was also awarded, along with John Hopfield, the 2024 Nobel Prize in Physics for \"foundational discoveries and inventions that enable machine learning with artificial neural networks\".\\nIn May 2023, Hinton announced his resignation from Google to be able to \"freely speak out about the risks of A.I.\" He has voiced concerns about deliberate misuse by malicious actors, technological unemployment, and existential risk from artificial general intelligence. He noted that establishing safety guidelines will require cooperation among those competing in use of AI in order to avoid the worst outcomes. After receiving the Nobel Prize, he called for urgent research into AI safety to figure out how to control AI systems smarter than humans.\\n\\nPage: LeNet\\nSummary: LeNet is a series of convolutional neural network architectures created by a research group in AT&T Bell Laboratories during the 1988 to 1998 period, centered around Yann LeCun. They were designed for reading small grayscale images of handwritten digits and letters, and were used in ATM for reading cheques.\\nConvolutional neural networks are a kind of feed-forward neural network whose artificial neurons can respond to a part of the surrounding cells in the coverage range and perform well in large-scale image processing. LeNet-5 was one of the earliest convolutional neural networks and was historically important during the development of deep learning.\\nIn general, when LeNet is referred to without a number, it refers to the 1998 version, the most well-known version. It is also sometimes called LeNet-5.\\n\\n', name='wikipedia', id='1fc8a7fa-b235-482d-9933-9fe634b4f34b', tool_call_id='call_16AakoNXIesV3Vqv2cIDMKNC'), ToolMessage(content=\"Soisy - sous - Montmorency - La rue de Montmorency vers 1900. La loi Loucheur en 1921 provoque une nouvelle vague de constructions qui feront cro√Ætre la population jusqu'√† 7 000 habitants en 1954 et 13 000 en 1964. The forecast for Soisy - sous - Montmorency on June 6 is partly cloudy and warm. The temperature will vary from 16 to 22¬∞ during the day and around 16¬∞ during the night. Expected wind conditions are pleasant with a steady gentle breeze of 15 km/h and gusts of 45 km/h. Soisy - sous - Montmorency Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Soisy - sous - Montmorency area. Soisy - sous - Montmorency - Weather forecast from Theweather.com. Weather conditions with updates on temperature , humidity, wind speed, snow, pressure, etc. for Soisy - sous - Montmorency , Val-d¬¥Oise. View the latest weather forecasts, maps, news and alerts on Yahoo Weather. Find local weather forecasts for Soisy - sous - Montmorency , France throughout the world.\", name='duckduckgo_search', id='20d60473-b523-4c33-95e9-a106fdd5324c', tool_call_id='call_Zkjs48z1DVnXBEcCrlqNW8XU'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 987, 'prompt_tokens': 6357, 'total_tokens': 7344, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 960, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 4992}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfPDrku5V6TtkXoP9aSvuOV870fD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--89c429fc-4370-44ed-b94c-326412e5e316-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Yann LeCun birthplace'}, 'id': 'call_8lMDVWaloDAdKxU0ugdsy3yf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 6357, 'output_tokens': 987, 'total_tokens': 7344, 'input_token_details': {'audio': 0, 'cache_read': 4992}, 'output_token_details': {'audio': 0, 'reasoning': 960}}), ToolMessage(content=\"Page: Peter Higgs\\nSummary: Peter Ware Higgs (29 May 1929 ‚Äì 8 April 2024) was a British theoretical physicist, professor at the University of Edinburgh, and Nobel laureate in Physics for his work on the mass of subatomic particles.\\nIn 1964, Higgs was the single author of one of the three milestone papers published in Physical Review Letters (PRL) that proposed that spontaneous symmetry breaking in electroweak theory could explain the origin of mass of elementary particles in general and of the W and Z bosons in particular. This Higgs mechanism predicted the existence of a new particle, the Higgs boson, the detection of which became one of the great goals of physics. In 2012, CERN announced the discovery of the Higgs boson at the Large Hadron Collider. The Higgs mechanism is generally accepted as an important ingredient in the Standard Model of particle physics, without which certain particles would have no mass.\\nFor this work, Higgs received the Nobel Prize in Physics, which he shared with Fran√ßois Englert in 2013.\\n\\n\\n\\nPage: CERN\\nSummary: The European Organization for Nuclear Research, known as CERN (; French pronunciation: [s…õ Ån]; Organisation europ√©enne pour la recherche nucl√©aire), is an intergovernmental organization that operates the largest particle physics laboratory in the world. Established in 1954, it is based in Meyrin, a western suburb of Geneva, on the France‚ÄìSwitzerland border. It comprises 24 member states. Israel, admitted in 2013, is the only full member geographically out of Europe. CERN is an official United Nations General Assembly observer.\\nThe acronym CERN is also used to refer to the laboratory; in 2024, it had 2704 scientific, technical, and administrative staff members, and hosted about 12406 users from institutions in more than 80 countries. In 2016, CERN generated 49 petabytes of data.\\nCERN's main function is to provide the particle accelerators and other infrastructure needed for high-energy physics research ‚Äì consequently, numerous experiments have been constructed at CERN through international collaborations. CERN is the site of the Large Hadron Collider (LHC), the world's largest and highest-energy particle collider. The main site at Meyrin hosts a large computing facility, which is primarily used to store and analyze data from experiments, as well as simulate events. As researchers require remote access to these facilities, the lab has historically been a major wide area network hub. CERN is also the birthplace of the World Wide Web.\", name='wikipedia', id='94aa00e4-ad45-4a79-bcb6-7b28489a2581', tool_call_id='call_8lMDVWaloDAdKxU0ugdsy3yf'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 547, 'prompt_tokens': 6907, 'total_tokens': 7454, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 6144}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfPMg9nPkGrsJTLCRvvrAzjqo7vd', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--1b8beb36-3d7d-4e81-b9d8-9de21df10dbf-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Yann LeCun birthplace Soisy-sous-Montmorency'}, 'id': 'call_jXfcKrDnsBYjFdJv7FMNQWAL', 'type': 'tool_call'}], usage_metadata={'input_tokens': 6907, 'output_tokens': 547, 'total_tokens': 7454, 'input_token_details': {'audio': 0, 'cache_read': 6144}, 'output_token_details': {'audio': 0, 'reasoning': 512}}), ToolMessage(content='No good Wikipedia Search Result was found', name='wikipedia', id='103c06cc-fb55-421d-9732-13b418b19757', tool_call_id='call_jXfcKrDnsBYjFdJv7FMNQWAL'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 986, 'prompt_tokens': 6954, 'total_tokens': 7940, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 960, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 6784}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfPQldqUJMSLnJ3T2YipesW5SN2k', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--287e34bd-d610-4492-adcf-f11c3975db0d-0', tool_calls=[{'name': 'wikipedia', 'args': {'query': 'Yann LeCun'}, 'id': 'call_MTeuNdbNLySTsjaw1UsYbmTa', 'type': 'tool_call'}], usage_metadata={'input_tokens': 6954, 'output_tokens': 986, 'total_tokens': 7940, 'input_token_details': {'audio': 0, 'cache_read': 6784}, 'output_token_details': {'audio': 0, 'reasoning': 960}}), ToolMessage(content='Page: Yann LeCun\\nSummary: Yann Andr√© Le Cun ( l…ô-KUN, French: [l…ôk≈ìÃÉ]; usually spelled LeCun; born 8 July 1960) is a French-American computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics and computational neuroscience. He is the Jacob T. Schwartz Professor of Computer Science at the Courant Institute of Mathematical Sciences at New York University and Chief Artificial Intelligence (AI) Scientist at Meta.\\nHe is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs). He is also one of the main creators of the DjVu image compression technology, alongside L√©on Bottou and Patrick Haffner. He co-developed the Lush programming language with L√©on Bottou.\\nIn 2018, LeCun, Yoshua Bengio, and Geoffrey Hinton, received the Turing Award for their work on deep learning. The three are sometimes referred to as the \"Godfathers of AI\" and \"Godfathers of Deep Learning\".\\n\\nPage: Geoffrey Hinton\\nSummary: Geoffrey Everest Hinton (born 6 December 1947) is a British-Canadian computer scientist, cognitive scientist, and cognitive psychologist known for his work on artificial neural networks, which earned him the title \"the Godfather of AI\".\\nHinton is University Professor Emeritus at the University of Toronto. From 2013 to 2023, he divided his time working for Google Brain and the University of Toronto before publicly announcing his departure from Google in May 2023, citing concerns about the many risks of artificial intelligence (AI) technology. In 2017, he co-founded and became the chief scientific advisor of the Vector Institute in Toronto.\\nWith David Rumelhart and Ronald J. Williams, Hinton was co-author of a highly cited paper published in 1986 that popularised the backpropagation algorithm for training multi-layer neural networks, although they were not the first to propose the approach. Hinton is viewed as a leading figure in the deep learning community. The image-recognition milestone of the AlexNet designed in collaboration with his students Alex Krizhevsky and Ilya Sutskever for the ImageNet challenge 2012 was a breakthrough in the field of computer vision.\\nHinton received the 2018 Turing Award, together with Yoshua Bengio and Yann LeCun for their work on deep learning. They are sometimes referred to as the \"Godfathers of Deep Learning\" and have continued to give public talks together. He was also awarded, along with John Hopfield, the 2024 Nobel Prize in Physics for \"foundational discoveries and inventions that enable machine learning with artificial neural networks\".\\nIn May 2023, Hinton announced his resignation from Google to be able to \"freely speak out about the risks of A.I.\" He has voiced concerns about deliberate misuse by malicious actors, technological unemployment, and existential risk from artificial general intelligence. He noted that establishing safety guidelines will require cooperation among those competing in use of AI in order to avoid the worst outcomes. After receiving the Nobel Prize, he called for urgent research into AI safety to figure out how to control AI systems smarter than humans.\\n\\nPage: LeNet\\nSummary: LeNet is a series of convolutional neural network architectures created by a research group in AT&T Bell Laboratories during the 1988 to 1998 period, centered around Yann LeCun. They were designed for reading small grayscale images of handwritten digits and letters, and were used in ATM for reading cheques.\\nConvolutional neural networks are a kind of feed-forward neural network whose artificial neurons can respond to a part of the surrounding cells in the coverage range and perform well in large-scale image processing. LeNet-5 was one of the earliest convolutional neural networks and was historically important during the development of deep learning.\\nIn general, when LeNet is referred to without a number, it refers to the 1998 version, the most well-known version. It is also sometimes called LeNet-5.\\n\\n', name='wikipedia', id='171d8354-cb9c-4aba-95c8-3ae0d3a2216a', tool_call_id='call_MTeuNdbNLySTsjaw1UsYbmTa'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 999, 'prompt_tokens': 7812, 'total_tokens': 8811, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 960, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 6784}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfPZtXpHJ3MaXwuoBmc4BlOtifZl', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--1ee79777-3238-446f-85c5-1f5ec3775fc0-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Yann LeCun birthplace Soisy-sous-Montmorency'}, 'id': 'call_XDxiSR4XRnk5ZryhrDtVGAmN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 7812, 'output_tokens': 999, 'total_tokens': 8811, 'input_token_details': {'audio': 0, 'cache_read': 6784}, 'output_token_details': {'audio': 0, 'reasoning': 960}}), ToolMessage(content='2 days ago - LeCun was born on 8 July 1960, at Soisy-sous-Montmorency in the suburbs of Paris . His name, Le Cun, originates from the old Breton form Le Cunff, and was from the region of Guingamp in northern Brittany. \"Yann\" is the Breton form for \"John\". 18 hours ago - Yann Le Cun [l…ôk≈ìÃÉ], n√© le 8 juillet 1960 √† Soisy-sous-Montmorency , est le directeur scientifique de l\\'IA de Meta, et chercheur en intelligence artificielle et vision artificielle (robotique) franco-am√©ricain. June 12, 2025 - \\'Soisy under Montmorency\\') is a commune in the Val-d\\'Oise department located 15.3 km (9.5 mi) north of Paris, France . 7 hours ago - The news of the 65-year-old professor, ... but believes is already beginning to happen. Born in 1960 in Soisy-sous-Montmorency, a small town north of Paris in France , LeCun became fascinated by artificial intelligence after watching ... 5 days ago - In 2019, he received the ACM Turing Award alongside Geoffrey Hinton and Yoshua Bengio for breakthroughs that made deep neural networks a critical component of modern computing. Born in Soisy-sous-Montmorency, France , on July 8, 1960, LeCun ...', name='duckduckgo_search', id='97461ccb-a81d-42d0-9a31-1b1bdac46ae6', tool_call_id='call_XDxiSR4XRnk5ZryhrDtVGAmN'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 484, 'prompt_tokens': 8163, 'total_tokens': 8647, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 7680}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfPgBVokhsdTJ72M7e64AysIzZAe', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--6c2e4d49-aa01-427f-9990-cdbb0788f036-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature now'}, 'id': 'call_nG1zKvS1QQpBo9ArChnfhfQT', 'type': 'tool_call'}], usage_metadata={'input_tokens': 8163, 'output_tokens': 484, 'total_tokens': 8647, 'input_token_details': {'audio': 0, 'cache_read': 7680}, 'output_token_details': {'audio': 0, 'reasoning': 448}}), ToolMessage(content=\"April 27, 2025 - Soisy-sous-Montmorency est desservie par la gare du Champ de courses d'Enghien, sur le r√©seau Transilien Paris-Nord, branches Paris-Nord ‚Äî Pontoise/Persan-Beaumont. La gare est desservie √† raison d'un train omnibus tous les 15 minutes en heures creuses et √† la m√™me fr√©quence en heures de pointe, les trains devenant en revanche semi-directs. September 14, 2025 - The forecast for Soisy-sous-Montmorency today is mostly cloudy and warm. The temperature will vary from 54 to 66¬∞ during the day and 54 to 55¬∞ during the night . A consistent gentle breeze of 10 mph and gusts of up to 26 mph are anticipated. August 31, 2025 - Montmorency (2km) Saint-Gratien (2km) Domont (5km) Saint-Brice-sous-For√™t (5km) Montmagny (4km) Villetaneuse (5km) October 10, 2025 - Premi√®re semaine (jusqu'au vendredi 17 octobre) : M√©t√©ocity pr√©voit entre 10¬∞C et 18¬∞C √† Soisy-sous-Montmorency. La temp√©rature moyenne sera en hausse de 1¬∞C environ par rapport √† √† celle d'aujourd'hui, vendredi 10 octobre. September 12, 2025 - A brief summary of the Soisy-sous-Montmorency weather now, today, tomorrow and the coming days ¬∑ The current Soisy-sous-Montmorency weather right now according to the weather station\", name='duckduckgo_search', id='c02e7903-e22d-47d1-90ba-9efd25cf951b', tool_call_id='call_nG1zKvS1QQpBo9ArChnfhfQT'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 612, 'prompt_tokens': 8548, 'total_tokens': 9160, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 7936}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfPlkBduMFV2babGDpJng0b1FBbB', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--ad04454d-b150-4653-86e7-0ffa601b3ce8-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature now'}, 'id': 'call_5UlSWvckCf28HFNzH3f2fT9t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 8548, 'output_tokens': 612, 'total_tokens': 9160, 'input_token_details': {'audio': 0, 'cache_read': 7936}, 'output_token_details': {'audio': 0, 'reasoning': 576}}), ToolMessage(content='The temperatures are highest on average in July, at around 20.1 ¬∞C (68.2 ¬∞F), and lowest in January, at around 4.7 ¬∞C (40.5 ¬∞F). The temperatures are highest on average in July, at around 20.5 ¬∞C (68.9 ¬∞F), and lowest in January, at around 5.3 ¬∞C (41.5 ¬∞F). ... Open now ... Are you currently on your trip? ... Open now ... Are you currently on your trip? Soisy - sous - Montmorency , France - Current temperature and weather conditions. Detailed hourly weather forecast for today - including weather conditions, temperature , pressure, humidity, precipitation, dewpoint, wind, visibility, and UV index data.', name='duckduckgo_search', id='3c4783dd-026d-4239-a811-d5c77a32b4cb', tool_call_id='call_5UlSWvckCf28HFNzH3f2fT9t'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1124, 'prompt_tokens': 8749, 'total_tokens': 9873, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1088, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 8320}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfPrEqeeiNayvaNuKDbZS2dsLOp0', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f17aad32-75d7-40e4-9d40-1566fb6c5c5b-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature now'}, 'id': 'call_GtCvMNH3GCNjVsbd7bCbuCTz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 8749, 'output_tokens': 1124, 'total_tokens': 9873, 'input_token_details': {'audio': 0, 'cache_read': 8320}, 'output_token_details': {'audio': 0, 'reasoning': 1088}}), ToolMessage(content=\"April 27, 2025 - Soisy-sous-Montmorency est desservie par la gare du Champ de courses d'Enghien, sur le r√©seau Transilien Paris-Nord, branches Paris-Nord ‚Äî Pontoise/Persan-Beaumont. La gare est desservie √† raison d'un train omnibus tous les 15 minutes en heures creuses et √† la m√™me fr√©quence en heures de pointe, les trains devenant en revanche semi-directs. September 14, 2025 - The forecast for Soisy-sous-Montmorency today is mostly cloudy and warm. The temperature will vary from 54 to 66¬∞ during the day and 54 to 55¬∞ during the night . A consistent gentle breeze of 10 mph and gusts of up to 26 mph are anticipated. August 31, 2025 - Montmorency (2km) Saint-Gratien (2km) Domont (5km) Saint-Brice-sous-For√™t (5km) Montmagny (4km) Villetaneuse (5km) October 10, 2025 - Premi√®re semaine (jusqu'au vendredi 17 octobre) : M√©t√©ocity pr√©voit entre 10¬∞C et 18¬∞C √† Soisy-sous-Montmorency. La temp√©rature moyenne sera en hausse de 1¬∞C environ par rapport √† √† celle d'aujourd'hui, vendredi 10 octobre. September 12, 2025 - A brief summary of the Soisy-sous-Montmorency weather now, today, tomorrow and the coming days ¬∑ The current Soisy-sous-Montmorency weather right now according to the weather station\", name='duckduckgo_search', id='96f13b1d-2ee5-46fb-b2cc-ce5b683a2345', tool_call_id='call_GtCvMNH3GCNjVsbd7bCbuCTz'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1125, 'prompt_tokens': 9134, 'total_tokens': 10259, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1088, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 8576}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfQ0RFwtw8lsHUCC2gCinwUZ0dgx', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--a9b4c34d-14cc-466b-a028-9d37715ceb91-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature now weather'}, 'id': 'call_DDSFYr2XV1Ergl3AW3xcEAIp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 9134, 'output_tokens': 1125, 'total_tokens': 10259, 'input_token_details': {'audio': 0, 'cache_read': 8576}, 'output_token_details': {'audio': 0, 'reasoning': 1088}}), ToolMessage(content=\"Soisy - sous - Montmorency , France - Current temperature and weather conditions. Detailed hourly weather forecast for today - including weather conditions, temperature , pressure, humidity, precipitation, dewpoint, wind, visibility, and UV index data. The current Soisy - sous - Montmorency weather right now according to the weather station.Two-week Soisy - sous - Montmorency weather forecast for the next 14 days. Accurate Soisy - sous - Montmorency weather today, forecast for sun, rain, wind and temperature . Soisy - sous - Montmorency - Weather forecast from Theweather.com. Weather conditions with updates on temperature , humidity, wind speed, snow, pressure, etc. for Soisy - sous - Montmorency , Val-d¬¥Oise. Use Current Location. Recent. Soisy - sous - Montmorency . Val-d'Oise.By analyzing current weather conditions, how the weather is forecasted to change, and other factors like location, you can identify the risk of experiencing health-related symptoms.\", name='duckduckgo_search', id='0af4372f-5d93-4ef1-972a-c833f5b56cde', tool_call_id='call_DDSFYr2XV1Ergl3AW3xcEAIp'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 868, 'prompt_tokens': 9387, 'total_tokens': 10255, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 832, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1408}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfQ9xtfuIflTjGvNTOalKVOKssSW', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f274e6e3-5b64-412d-8356-53cb91600572-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature now weather'}, 'id': 'call_QkOp1hD8S5wbuBHpZvv2rkKX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 9387, 'output_tokens': 868, 'total_tokens': 10255, 'input_token_details': {'audio': 0, 'cache_read': 1408}, 'output_token_details': {'audio': 0, 'reasoning': 832}}), ToolMessage(content=\"Current local time in USA ‚Äì Illinois ‚Äì Chicago. Get Chicago's weather and area codes, time zone and DST. Explore Chicago's sunrise and sunset, moonrise and moonset. Nov 7, 2025 ¬∑ Exact time now, time zone, time difference, sunrise/sunset time and key facts for Chicago, Illinois, United States. 1 day ago ¬∑ Exact time in Chicago time zone now. Official Chicago timezone and time change dates for year 2025. Current local time in Chicago, Illinois, United States. Get maps, travel information, Chicago Timezone and CST. 3 days ago ¬∑ Get the current time in Chicago, United States üá∫üá∏ with Time.now. Find info about timezone, daylight savings and more for Chicago here.\", name='duckduckgo_search', id='996e14b6-9159-4b0e-98ba-5b171410bd84', tool_call_id='call_QkOp1hD8S5wbuBHpZvv2rkKX'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 613, 'prompt_tokens': 9584, 'total_tokens': 10197, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 9216}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfQHgRULR6L6YRfa5xQB38qJxiy5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--8a4c0664-a1d9-4ceb-b341-b7e49a9ca91c-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current weather temperature now'}, 'id': 'call_pwTA7oypfXYhjxMsRpP4K7ED', 'type': 'tool_call'}], usage_metadata={'input_tokens': 9584, 'output_tokens': 613, 'total_tokens': 10197, 'input_token_details': {'audio': 0, 'cache_read': 9216}, 'output_token_details': {'audio': 0, 'reasoning': 576}}), ToolMessage(content=\"June 12, 2025 - 'Soisy under Montmorency') is a commune in the Val-d'Oise department located 15.3 km (9.5 mi) north of Paris, France. September 14, 2025 - Max. precipitation chance ... The forecast for Soisy-sous-Montmorency today is mostly cloudy and warm. The temperature will vary from 54 to 66¬∞ during the day and 54 to 55¬∞ during the night . October 10, 2025 - Premi√®re semaine (jusqu'au vendredi 17 octobre) : M√©t√©ocity pr√©voit entre 10¬∞C et 18¬∞C √† Soisy-sous-Montmorency. La temp√©rature moyenne sera en hausse de 1¬∞C environ par rapport √† √† celle d'aujourd'hui, vendredi 10 octobre. September 12, 2025 - Analyze the Soisy-sous-Montmorency centered high definition weather maps with hourly weather forecasts for precipitation, cloud cover, wind animation, temperature, atmospheric pressure and air quality index. September 20, 2025 - La m√©t√©o des agriculteurs √† Soisy-sous-Montmorency (95230, Val d'Oise) sur 15 jours : Pr√©visions agricoles, temp√©ratures mini/maxi, pr√©vision humidit√©, ETP, temp√©rature du sol, √©vapotranspiration et donn√©es pour l'agriculture et le jardinage.\", name='duckduckgo_search', id='e8ccb574-a725-4672-83b9-960433332274', tool_call_id='call_pwTA7oypfXYhjxMsRpP4K7ED'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1060, 'prompt_tokens': 9915, 'total_tokens': 10975, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1024, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 8960}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfQMCKsReUYYHDE28VxTG3OBwNKf', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--618683f0-5b26-4fcc-a09b-34844f356f07-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency current temperature now'}, 'id': 'call_PFaPtVvi3bCw2ozCVwWzmIVV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 9915, 'output_tokens': 1060, 'total_tokens': 10975, 'input_token_details': {'audio': 0, 'cache_read': 8960}, 'output_token_details': {'audio': 0, 'reasoning': 1024}}), ToolMessage(content=\"April 27, 2025 - Soisy-sous-Montmorency est desservie par la gare du Champ de courses d'Enghien, sur le r√©seau Transilien Paris-Nord, branches Paris-Nord ‚Äî Pontoise/Persan-Beaumont. La gare est desservie √† raison d'un train omnibus tous les 15 minutes en heures creuses et √† la m√™me fr√©quence en heures de pointe, les trains devenant en revanche semi-directs. Soisy - sous - Montmorency , France - Current temperature and weather conditions. Detailed hourly weather forecast for today - including weather conditions, temperature , pressure, humidity, precipitation, dewpoint, wind, visibility, and UV index data. The current Soisy - sous - Montmorency weather right now according to the weather station. Accurate Soisy - sous - Montmorency weather today, forecast for sun, rain, wind and temperature . Soisy - sous - Montmorency Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Soisy - sous - Montmorency area.\", name='duckduckgo_search', id='de4d92e5-2409-482e-95d3-7628d710fa5b', tool_call_id='call_PFaPtVvi3bCw2ozCVwWzmIVV'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1828, 'prompt_tokens': 10186, 'total_tokens': 12014, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1792, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 9728}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfQVl3KjqZDRlZR2sib8IeC17gFC', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--124861aa-eef3-4b29-ae4f-65c114cef830-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Soisy-sous-Montmorency weather today temperature'}, 'id': 'call_fJsbFpn1c5G8vvuYqra0EBIC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 10186, 'output_tokens': 1828, 'total_tokens': 12014, 'input_token_details': {'audio': 0, 'cache_read': 9728}, 'output_token_details': {'audio': 0, 'reasoning': 1792}}), ToolMessage(content='Soisy - Sous - Montmorency , France weather forecasted for the next 10 days will have maximum temperature of 10¬∞c / 50¬∞f on Tue 04. Sannois, France weather forecasted for the next 10 days will have maximum temperature of 28¬∞c / 82¬∞f on Thu 12. ... like to know what the weather ... Epinay-Sur-Seine, France weather forecasted for the next 10 days will have maximum temperature of 27¬∞c / 80¬∞f on Thu 01. Enghien-Les-Bains, France weather forecasted for the next 10 days will have maximum temperature of 41¬∞c / 105¬∞f on Wed 02. Temperatures will vary between 11 and 15¬∞C. ... Normal temperature : 10¬∞C Average, today : 13¬∞C One year ago : 12¬∞C', name='duckduckgo_search', id='696c0b64-57a5-477d-99f7-4f5c00c498bc', tool_call_id='call_fJsbFpn1c5G8vvuYqra0EBIC'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 676, 'prompt_tokens': 10415, 'total_tokens': 11091, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 640, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 9344}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfQgDACvvXhXfod4JPfiSM5svOab', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--b7b9d76c-7006-4fad-9490-264c00862a81-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Temp√©rature actuelle Soisy-sous-Montmorency'}, 'id': 'call_mEQCJXupEk3R7XYsqByVlVB2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 10415, 'output_tokens': 676, 'total_tokens': 11091, 'input_token_details': {'audio': 0, 'cache_read': 9344}, 'output_token_details': {'audio': 0, 'reasoning': 640}}), ToolMessage(content='METEO FRANCE - Retrouvez les pr√©visions METEO SOISY - SOUS - MONTMORENCY de M√©t√©o-France pour aujourd‚Äôhui, demain et jusqu‚Äô√† 15 jours, ainsi que les pr√©visions m√©t√©os locales par heure et les pr√©visions de pluie. Soisy - sous - Montmorency , France - Current temperature and weather conditions. Detailed hourly weather forecast for today - including weather conditions, temperature , pressure, humidity, precipitation, dewpoint, wind, visibility, and UV index data. Latest consultations. Weather in Soisy - sous - Montmorency . √éle-de-France. Updated: 16/5/2025 a las 08:00.Humidity. 47%. Dew temperature . 7¬∞. Clouds. Soisy - sous - Montmorency Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Soisy - sous - Montmorency area. Weather in Soisy - sous - Montmorency for 10 days. Temperature , ¬∞C. feels like. Pressure, hPa.', name='duckduckgo_search', id='1dacf928-bedc-4201-9ab4-c0e5673ae39b', tool_call_id='call_mEQCJXupEk3R7XYsqByVlVB2'), AIMessage(content='- Current Chief AI Scientist at Meta AI: Yann LeCun.\\n- Born: July 8, 1960.\\n- Born in: Soisy-sous-Montmorency, Val-d‚ÄôOise, √éle-de-France, France (near Paris).\\n\\nCurrent temperature there: I can look up a live current temperature if you‚Äôd like. Do you want me to fetch the latest reading for Soisy-sous-Montmorency now?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1444, 'prompt_tokens': 10681, 'total_tokens': 12125, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1344, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 10240}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcfQmZAKxRuQ1I8ksbBX7ZLCad2sx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2e839f66-c3d2-402c-9cb7-2daa6ebf4084-0', usage_metadata={'input_tokens': 10681, 'output_tokens': 1444, 'total_tokens': 12125, 'input_token_details': {'audio': 0, 'cache_read': 10240}, 'output_token_details': {'audio': 0, 'reasoning': 1344}})]}\n"
     ]
    }
   ],
   "source": [
    "# initialize the agent\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant that can search for information using available tools.\"\n",
    ")\n",
    "\n",
    "# Run with messages format\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX2wNbmMdy3P"
   },
   "source": [
    "### Dynamic model\n",
    "\n",
    "[Dynamic agent model](https://docs.langchain.com/oss/python/langchain/agents#dynamic-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "npHfFqHxdy_R"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import AgentMiddleware\n",
    "from langchain.messages import AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "basic_model = ChatOpenAI(model=\"gpt-5-nano-2025-08-07\")\n",
    "advanced_model = ChatOpenAI(model=\"gpt-5-mini-2025-08-07\")\n",
    "\n",
    "\n",
    "class DynamicModelMiddleware(AgentMiddleware):\n",
    "\n",
    "    def wrap_model_call(self, request, handler):\n",
    "        if len(request.state[\"messages\"]) > self.messages_threshold:\n",
    "            request.model = advanced_model\n",
    "        else:\n",
    "            request.model = basic_model\n",
    "\n",
    "        return handler(request)\n",
    "\n",
    "    def __init__(self, messages_threshold: int) -> None:\n",
    "        self.messages_threshold = messages_threshold\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,\n",
    "    tools=tools,\n",
    "    middleware=[DynamicModelMiddleware(messages_threshold=2)] # was 5 changed to 2 for testing\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 0: {'messages': [HumanMessage(content='What is the capital of France?', additional_kwargs={}, response_metadata={}, id='7866c6ea-7a9e-4843-b444-541095c22f81'), AIMessage(content='Paris', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 202, 'prompt_tokens': 219, 'total_tokens': 421, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CeKeF3XHzfuLATLdZykUUoyE6ZBhH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--56402925-6f09-4d8c-bd66-e3571f028a5f-0', usage_metadata={'input_tokens': 219, 'output_tokens': 202, 'total_tokens': 421, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})]}\n",
      "Query 1: {'messages': [HumanMessage(content=\"Who wrote 'To Kill a Mockingbird'?\", additional_kwargs={}, response_metadata={}, id='c1cce845-b070-4313-8097-00c79222ca60'), AIMessage(content='Harper Lee. It was published in 1960.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 277, 'prompt_tokens': 222, 'total_tokens': 499, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CeKeHepeHqbyC5SSUbCXDh7SyATj7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--1bc51cc4-ce72-4e38-8dd0-597287cb5651-0', usage_metadata={'input_tokens': 222, 'output_tokens': 277, 'total_tokens': 499, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})]}\n",
      "Query 2: {'messages': [HumanMessage(content='Explain the theory of relativity.', additional_kwargs={}, response_metadata={}, id='c1e21840-1175-45f0-a083-b5e526d0b629'), AIMessage(content=\"Here's a concise, accessible overview of the theory of relativity, which actually comes in two parts: Special Relativity (SR) and General Relativity (GR).\\n\\n- What it is in brief\\n  - Relativity is a physical framework that changes how we think about space, time, and gravity. It shows that measurements of time, distance, and simultaneity depend on your motion, and, in the presence of mass-energy, gravity is described as the curvature of spacetime.\\n\\n1) Special Relativity (SR) ‚Äî about motion at high speeds, no gravity\\n- Core postulates\\n  - The laws of physics are the same in all inertial frames (no preferred state of rest).\\n  - The speed of light in a vacuum is the same constant c for all observers, regardless of the light source or observer.\\n- Key consequences\\n  - Time dilation: a moving clock runs slower as seen by a stationary observer (factor Œ≥ = 1/‚àö(1 ‚àí v^2/c^2)).\\n  - Length contraction: objects moving relative to you are measured to be shorter along the direction of motion (also by factor Œ≥).\\n  - Relativity of simultaneity: whether two spatially separated events occur at the same time can depend on your frame of reference.\\n  - Mass‚Äìenergy equivalence: E = mc^2 (more generally, a moving object has energy E = Œ≥mc^2, and its kinetic energy increases with speed).\\n  - No faster-than-light travel for objects with rest mass: as you speed up toward c, it requires ever more energy, and you never quite reach c.\\n- Everyday illustrations\\n  - Time dilation and the twin paradox (paradox resolved by noting the traveling twin changes inertial frames during the trip).\\n  - GPS satellites must account for both special-relativistic time dilation (because they‚Äôre moving fast) and general-relativistic effects (because they‚Äôre higher in Earth's gravitational field).\\n\\n2) General Relativity (GR) ‚Äî gravity as the geometry of spacetime\\n- Core idea\\n  - The Equivalence Principle: being in a gravitational field is locally indistinguishable from being in an accelerated frame. In small regions of spacetime, you can‚Äôt tell gravity apart from acceleration.\\n  - Gravity is not a force in the Newtonian sense; it‚Äôs the bending of spacetime by mass and energy. Objects move along straightest possible paths (geodesics) in this curved spacetime.\\n- What the math describes (conceptual)\\n  - The presence of mass-energy tells spacetime how to curve.\\n  - The curvature of spacetime tells matter how to move.\\n  - The precise relationship is encoded in Einstein‚Äôs field equations (GŒºŒΩ = 8œÄG TŒºŒΩ, in simple terms), which connect curvature (geometry) to energy and momentum (matter and energy content).\\n- Predictions and confirmations\\n  - Gravitational time dilation: clocks closer to massive bodies run slower.\\n  - Light deflection by gravity: light bends when passing near massive objects (gravitational lensing).\\n  - Gravitational redshift: light climbing out of a gravitational well loses energy and shifts to red.\\n  - Perihelion precession of Mercury: orbit shifts explained by spacetime curvature.\\n  - Gravitational waves: ripples in spacetime detected directly by LIGO/Virgo.\\n  - Black holes and cosmology: GR describes intense gravity and the large-scale dynamics of the universe.\\n- Everyday and technological relevance\\n  - GPS accuracy depends on correcting both SR and GR time effects to keep positioning accurate.\\n  - Gravitational lensing provides a tool for studying distant galaxies and dark matter.\\n\\n3) How SR and GR relate to Newtonian physics\\n- In everyday speeds and weak gravity, both SR and GR reduce to Newton‚Äôs laws with small corrections. You get the familiar Newtonian gravity and classical mechanics as limits.\\n- SR is essential for high-speed physics (particle accelerators, GPS timing, etc.). GR is essential for strong gravity (near massive bodies like stars/planets) and cosmology (the expanding universe).\\n\\n4) Common misconceptions clarified\\n- ‚ÄúAbsolute rest‚Äù doesn‚Äôt exist. There is no universal, preferred frame of reference.\\n- Nothing travels faster than light in vacuum; c is the universal speed limit for information and causal effects.\\n- Time does not stop for a moving observer; each observer has their own valid experience of time, and all measurements agree on the speed of light being c.\\n- SR and GR don‚Äôt contradict quantum mechanics; integrating gravity with quantum theory (quantum gravity) is an ongoing area of research.\\n\\n5) When relativity matters\\n- Near-light speeds in particle physics\\n- Strong gravitational fields (near black holes, neutron stars)\\n- Precision timing and navigation systems (e.g., GPS)\\n- Cosmology and the large-scale structure and history of the universe\\n\\nIf you‚Äôd like, I can tailor this explanation to a specific aspect (for example, walk through a concrete example like the twin paradox, or give a simple derivation of time dilation, or explain the Einstein field equations at a high level).\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2269, 'prompt_tokens': 219, 'total_tokens': 2488, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1216, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CeKeLUr8Tv7KzZLQtETiF9KfCUnG7', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--89366163-04c3-4a0c-baae-536d0688c3bb-0', usage_metadata={'input_tokens': 219, 'output_tokens': 2269, 'total_tokens': 2488, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1216}})]}\n",
      "Query 3: {'messages': [HumanMessage(content='What are the benefits of functional programming?', additional_kwargs={}, response_metadata={}, id='ca016418-be02-4e06-bb49-4e17b9120068'), AIMessage(content='Here are common benefits people cite for functional programming (FP):\\n\\n- Predictable behavior and easier reasoning\\n  - Pure functions have no side effects and always yield the same output for the same input (referential transparency). That makes reasoning about code and proving correctness much easier.\\n\\n- Modularity and composability\\n  - Small, well-defined functions can be composed to build larger behavior. Higher-order functions and function pipelines let you assemble complex logic from reusable pieces.\\n\\n- Easier testing and debugging\\n  - Because functions are typically pure and data is immutable, tests are more local and deterministic. Fewer hidden dependencies reduce debugging effort.\\n\\n- Safety in concurrent and parallel execution\\n  - Immutability and lack of shared mutable state reduce data races, making it easier to run code concurrently or in parallel without tricky synchronization.\\n\\n- Maintainability and readability\\n  - Declarative style and clear data flows can lead to code that‚Äôs easier to read, understand, and refactor. Small, focused functions tend to be simpler to maintain.\\n\\n- Stronger data modeling and abstractions\\n  - Algebraic data types, pattern matching, and strong type systems (in many FP languages) help model domain concepts more precisely and catch errors early.\\n\\n- Better support for refactoring\\n  - Because behavior is expressed as pure functions and data flows are explicit, replacing implementations or reusing parts of logic tends to be safer and easier.\\n\\n- Rich tooling and testing approaches\\n  - Equational reasoning, property-based testing, and formal reasoning often align well with FP‚Äôs math-like foundations, enabling strong guarantees.\\n\\n- Expressive abstractions and abstractions reuse\\n  - FP emphasizes generic abstractions (functors, monads, currying, etc.) that can lead to powerful, reusable APIs and libraries.\\n\\n- Time-travel and state snapshots (in immutable models)\\n  - Immutability makes it natural to keep history, implement undo/redo, and inspect previous states without special plumbing.\\n\\n- Easier domain modeling for certain problems\\n  - Certain domains (data transformation, streaming, complex event processing) map well to FP concepts like pipelines and lazy evaluation.\\n\\n- Potential performance benefits (opportunities, not guarantees)\\n  - Laziness, parallelism, and optimizations from compilers can lead to efficient implementations in some contexts. But FP can introduce overhead in others, so results vary by language and problem.\\n\\nNote: The benefits you experience depend on the problem domain and the language you use. Some tasks benefit a lot from FP, while in others imperative or object-oriented approaches may be simpler. If you share your language and domain, I can tailor the list or give concrete examples.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1628, 'prompt_tokens': 220, 'total_tokens': 1848, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1088, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CeKeePpgHrGGGBbWamhZqZenZ2aOP', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--cf1e956a-874e-4ba2-9dbe-cc17553f1228-0', usage_metadata={'input_tokens': 220, 'output_tokens': 1628, 'total_tokens': 1848, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1088}})]}\n",
      "Query 4: {'messages': [HumanMessage(content='How does a blockchain work?', additional_kwargs={}, response_metadata={}, id='70f6e921-005d-4434-bf74-7ec4218e86e3'), AIMessage(content='Here‚Äôs a straightforward way to understand how a blockchain works.\\n\\nCore idea\\n- A blockchain is a distributed, append-only ledger shared among many participants. It records transactions in blocks that are cryptographically linked to the previous block, forming a chain.\\n\\nKey components\\n- Transactions: The individual records (e.g., someone sending digital currency to someone else).\\n- Blocks: Batches of transactions. Each block also contains a timestamp, a reference (hash) to the previous block, and usually a summary (like a Merkle root) of the transactions it contains.\\n- Hashes: A cryptographic fingerprint. Each block has a unique hash, and it includes the previous block‚Äôs hash. This links blocks together and makes tampering detectable.\\n- Network: Many computers (nodes) running software that validates transactions, maintains a copy of the ledger, and agrees on the current ‚Äútrue‚Äù chain.\\n\\nHow a transaction becomes part of the chain (typical public blockchain like Bitcoin or Ethereum)\\n1) A user creates a transaction and broadcasts it to the network.\\n2) Nodes validate the transaction (e.g., digital signatures, sufficient balance, no double-spend).\\n3) Valid transactions are grouped into a candidate block by miners/validators.\\n4) The network reaches consensus to add the block:\\n   - Proof of Work (PoW): Miners try to solve a computational puzzle; the first to solve it wins the right to add the block and gets a reward.\\n   - Proof of Stake (PoS) or other methods: Validators are chosen/rotate to propose and attest to blocks based on stake or votes.\\n5) The winning block is added to the chain, and all nodes update their copy of the ledger.\\n6) Transactions in confirmed blocks are considered more final as more blocks are added on top (e.g., ‚ÄúN confirmations‚Äù = N blocks after the transaction).\\n\\nWhy it‚Äôs secure\\n- Tamper resistance: If someone tries to alter a past transaction, the block‚Äôs hash changes, which breaks the link to the next block. To cover this, the attacker would need to redo work or overpower the majority of the network, which is practically hard on large networks.\\n- Decentralization: No single point of control. A copy of the ledger exists on many nodes, so consensus is required to change it.\\n\\nData structure basics\\n- Each block contains: a list of transactions, a timestamp, a nonce (in PoW), the block‚Äôs hash, and the previous block‚Äôs hash.\\n- Merkle tree: A cryptographic tree that proves a transaction is included in a block without exposing all transactions. The Merkle root is included in the block header.\\n\\nPublic vs private (permissioned) blockchains\\n- Public: Anyone can read, write, and participate in consensus (e.g., Bitcoin, Ethereum). Highly decentralized, but can be slower.\\n- Private/permissioned: Access is restricted to known participants (e.g., in a business or consortium). Often faster and more scalable but with more centralized control.\\n\\nCommon terms and concepts\\n- Finality: When a transaction is considered permanent. In PoW blockchains, finality is probabilistic‚Äîthe more blocks on top, the more final it becomes. Some PoS systems offer stronger finality guarantees.\\n- Gas/fees: In some platforms (like Ethereum), like paying for the computation and storage a transaction requires.\\n- Smart contracts: Programs that run on the blockchain and can automate tasks when conditions are met (e.g., automatic token transfers, multi-party agreements).\\n- Forks: When the blockchain diverges into two potential paths (soft fork or hard fork) due to changes in rules or consensus.\\n\\nCommon use cases\\n- Digital currencies (payments and transfers).\\n- Smart contracts and decentralized apps (DApps).\\n- Supply chain tracking, digital identity, and more‚Äîany scenario needing a tamper-resistant, shared ledger.\\n\\nA simple analogy\\n- Imagine a public ledger at a neighborhood meeting. Each page (block) lists several transactions (payments). Each page has a unique number and references the previous page‚Äôs number. People submit pages, and a trusted group uses a rule (consensus) to decide which page becomes part of the official book. Once a page is added and recognized by the group, changing earlier pages becomes extremely difficult because you‚Äôd have to rewrite many pages and outvote or overpower the entire group.\\n\\nIf you‚Äôd like, tell me what level you‚Äôre aiming for (high-level overview, beginner-friendly with an example, or technical details about a specific blockchain like Bitcoin or Ethereum, or about a specific topic like PoW vs PoS), and I can tailor the explanation.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1840, 'prompt_tokens': 218, 'total_tokens': 2058, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 896, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CeKesUM6tvkDrvJlHwyet4b6BtqRw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--25e1f759-b109-4bce-b184-936e0ed671e9-0', usage_metadata={'input_tokens': 218, 'output_tokens': 1840, 'total_tokens': 2058, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 896}})]}\n",
      "Query 5: {'messages': [HumanMessage(content=\"Can you summarize the plot of '1984' by George Orwell?\", additional_kwargs={}, response_metadata={}, id='c52ecafd-acf0-4e3f-b4f2-931440878d05'), AIMessage(content='Here‚Äôs a concise plot summary of 1984 by George Orwell:\\n\\n- Setting and premise: In a dystopian future, the superstate Oceania is ruled by the totalitarian Party, led by the nearly omnipresent Big Brother. The Party uses constant surveillance, propaganda, and ‚Äúnewspeak‚Äù to control every aspect of life.\\n\\n- Protagonist and his job: Winston Smith works at the Ministry of Truth, where he rewrites historical records to fit the Party‚Äôs changes. He privately resents the Party and dreams of rebellion.\\n\\n- Rebellion and relationship: Winston begins a forbidden affair with Julia and they secretly pursue acts of defiance, renting a room free from telescreens where they can express themselves.\\n\\n- Betrayal and capture: The couple is betrayed (in part by Mr. Charrington, who is revealed to be an agent of the Thought Police) and arrested. Winston is subjected to brutal torture and re-education in the Ministry of Love.\\n\\n- Torture and brainwashing: Winston endures the infamous Room 101 and other torments designed to break his spirit. He is forced to confront his deepest fears and ultimately betray Julia.\\n\\n- Submission and ending: After intense torture, Winston is released, fully broken. He accepts the Party‚Äôs reality and comes to love Big Brother, having lost his rebellious individuality.\\n\\nIf you‚Äôd like, I can also summarize the main themes (surveillance, language and thought control, power), or provide a character-by-character breakdown.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2037, 'prompt_tokens': 226, 'total_tokens': 2263, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1728, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CeKf95pslI8MGcrnT4CHe8yEZUKjd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f669c80e-d926-456e-89e4-db9c66d57787-0', usage_metadata={'input_tokens': 226, 'output_tokens': 2037, 'total_tokens': 2263, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1728}})]}\n",
      "Query 6: {'messages': [HumanMessage(content='What are the implications of quantum computing?', additional_kwargs={}, response_metadata={}, id='ed99e5a1-598b-430b-9c60-14e51d017d1e'), AIMessage(content='Short answer\\nQuantum computing could be transformative, especially in cryptography, science (like chemistry and materials), and certain optimization tasks. But it‚Äôs a long-term shift: practical, fault-tolerant quantum computers are not here yet, and progress will be incremental. In the meantime, the most urgent implication is cryptography: we need quantum-safe (post-quantum) cryptography and secure migration plans.\\n\\nKey implications, by topic\\n\\n1) Cryptography and security\\n- Threat to current public-key cryptography: many widely used schemes (e.g., RSA, ECC) could be broken by a sufficiently large quantum computer using Shor‚Äôs algorithm.\\n- Data-at-rest risk: encrypted data long-lived in archives could be decrypted in the future, so ‚Äústore now, decrypt later‚Äù is a concern for sensitive information.\\n- Need for quantum-safe cryptography: migration to post-quantum algorithms (e.g., lattice-based, code-based, or other PQC schemes) and cryptographic agility (easy switching of algorithms in software and protocols).\\n- Practical steps already underway: organizations are evaluating PQC options, updating protocols, and planning phased migrations; standards bodies (e.g., NIST) are progressing on standardizing quantum-safe algorithms.\\n- Near-term reality: hybrid encryption (a classical scheme plus a quantum-safe component) is a practical bridge during transition.\\n\\n2) Science and engineering\\n- Quantum simulation: quantum computers can, in principle, model quantum systems (molecules, materials) more efficiently than classical computers.\\n- Impact domains: drug discovery, catalysis, advanced materials, and oddly complex chemical reactions could see accelerated research and new discoveries.\\n- Practical caveat: useful, fault-tolerant quantum simulations require robust quantum hardware and error correction; current devices (NISQ era) have limited, noisy capabilities and are better suited for demonstrations than routine scientific breakthroughs.\\n\\n3) Optimization, logistics, and AI\\n- Potential speedups for certain problem classes: combinatorial optimization, portfolio optimization, scheduling, logistics, and some machine-learning tasks.\\n- Reality check: many proposed quantum advantages are problem-specific and require hardware and error-correction capabilities that are beyond present devices. Hybrid quantum-classical approaches are a more likely near-term use.\\n\\n4) Hardware and software challenges\\n- Decoherence and errors: quantum bits are fragile; error correction is essential for reliable computation.\\n- Resource needs: achieving fault tolerance requires many physical qubits per logical qubit; current estimates place practical, large-scale quantum computers years away.\\n- Diverse approaches: superconducting qubits, trapped ions, photonics, and other architectures each have trade-offs (scalability, temperature, connectivity, error rates).\\n\\n5) Economic, political, and societal implications\\n- Inequality and geopolitics: nations and companies that invest in quantum R&D may gain strategic advantages; potential for a quantum ‚Äúgap‚Äù if adoption is uneven.\\n- Workforce and education: demand for new skills in quantum information science, quantum programming, and quantum software.\\n- Privacy and governance: increased emphasis on cryptographic resilience, crypto-agility, and security standards; policy and regulatory considerations will evolve with standards.\\n- Dual-use and safety: quantum tech can be applied in beneficial or dual-use ways; responsible innovation and international cooperation will matter.\\n\\nWhat to do now (practical takeaways)\\n- For individuals and organizations:\\n  - Start planning for cryptographic agility: design systems to switch cryptographic algorithms without a full redesign.\\n  - Monitor PQC standards and migrate when appropriate standards are finalized for your use case.\\n  - Consider cryptography risk assessments in data retention policies, especially for long-lived secrets.\\n  - If you‚Äôre in R&D, explore pilot projects in quantum-safe cryptography and, where relevant, quantum-inspired or early-quantum algorithms for niche problems.\\n- For policymakers and leaders:\\n  - Invest in quantum R&D ecosystems, education, and standards development.\\n  - Encourage international collaboration on standards, norms, and secure migration practices.\\n- For developers and researchers:\\n  - Learn the basics of quantum information, quantum algorithms (e.g., Shor, Grover), and the concept of quantum error correction.\\n  - Stay informed about hardware progress and the status of PQC standards (e.g., ongoing work by NIST and other standards bodies).\\n\\nCommon questions\\n- Will quantum computers break today‚Äôs encryption soon? Not immediately. Large, fault-tolerant quantum computers are not here yet. But the threat is real enough that migration to quantum-safe cryptography is a priority for long-term data security.\\n- What‚Äôs the difference between quantum supremacy and quantum advantage? Supremacy refers to a quantum computer performing a task faster than any classical one (often a contrived benchmark). Quantum advantage means a quantum computer performing a useful, practical task better than classical methods.\\n- When will we get practical fault-tolerant quantum computers? Estimates vary widely. Expert opinion generally places significant milestones many years out, though progress is continuous and incremental.\\n\\nIf you‚Äôd like, I can tailor this to a specific sector (e.g., finance, healthcare, or defense) or give you a short checklist for preparing your organization for quantum-safe cryptography.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3226, 'prompt_tokens': 220, 'total_tokens': 3446, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2176, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CeKfRAS7pAa0BxSh7Je8heJxAWaQe', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--3f735de6-30bf-493e-a93b-c93bceeb9b36-0', usage_metadata={'input_tokens': 220, 'output_tokens': 3226, 'total_tokens': 3446, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 2176}})]}\n",
      "{'messages': [HumanMessage(content='What are the latest advancements in AI research?', additional_kwargs={}, response_metadata={}, id='9fc4d3e9-0581-40ed-9496-004f11a3e8c0'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 963, 'prompt_tokens': 221, 'total_tokens': 1184, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 832, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CeKfoufaCrwmge3USna1WAz0lRk3I', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--1e54a11a-05e5-4443-af40-6de6988b1ce3-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'latest advancements in AI research 2024 2025'}, 'id': 'call_hasNXq5VVFPM1Sh7Iwzx0XhR', 'type': 'tool_call'}, {'name': 'duckduckgo_search', 'args': {'query': 'foundation models trends 2024 2025'}, 'id': 'call_ZZ4JLC66EkLSvwP1T6vu7CA8', 'type': 'tool_call'}, {'name': 'duckduckgo_search', 'args': {'query': 'multimodal AI models 2024 2025 advancements'}, 'id': 'call_ifJNVnU3DYStWwNX9QZe5L3C', 'type': 'tool_call'}, {'name': 'duckduckgo_search', 'args': {'query': 'AI safety alignment 2024 2025 developments'}, 'id': 'call_LHbfryND7uQqSiwMOqfXUutC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 963, 'total_tokens': 1184, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 832}}), ToolMessage(content='Get the latest news, advances in research , policy work, and education program updates from HAI in your inbox weekly.New this Year: The Official Chinese Version of the 2025 AI Index Report. The state of AI in 2025 : Agents, innovation, and transformation. November 5, 2025 | Survey. Almost all survey respondents say their organizations are using AI , and many have begun to use AI agents. The 2024 MAD (Machine Learning, AI , & Data) landscape showcases a significant expansion, featuring 2,011 logos, an increase from 1,416 the previous year. This growth includes 578 newcomers, a stark contrast to the initial 2012 version, which featured only 139 logos. In January 2025 , China-based AI startup DeepSeek (Ê∑±Â∫¶Ê±ÇÁ¥¢) released DeepSeek-R1, a high-quality large language model (LLM) that allegedly cost much less to develop and operate than Western competitors‚Äô alternatives. Today, we‚Äôre sharing the latest updates to Gemini, your AI assistant, including Deep Research ‚Äî our new agentic feature in Gemini Advanced ‚Äî and access to try Gemini 2.0 Flash, our latest experimental model.', name='duckduckgo_search', id='0a32aae5-460c-4444-81bc-e40d63c3e70d', tool_call_id='call_hasNXq5VVFPM1Sh7Iwzx0XhR'), ToolMessage(content='‰ΩÜÊòØËøôÁßçËøΩÊ†πÊ∫ØÊ∫êÂØπÊâæÂá∫foundationÂíåfundamentÁöÑÂå∫Âà´Âπ∂Ê≤°Êúâ‰ªÄ‰πàÂÆûÈôÖ‰∏äÁöÑÂ∏ÆÂä©„ÄÇ ‚ÄúÂéÜÂè≤XX‰∏çÂÖ∑ÊúâÁé∞ÂÆûÊÑè‰πâ‚ÄùÔºåÊîæÂú®foundationÂíåfundament‰∏äÂÜçÂêàÈÄÇ‰∏çËøá‰∫Ü„ÄÇ Áé∞Âú®‰Ω†ÊâæÂá∫ÂçÅ‰∏™Â∏¶ÊúâfoundationÁöÑ ‚Ä¶ „ÄäAdvances and Challenges in Foundation Agents„Äã‰∏∫Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂ∫îÁî®Êèê‰æõ‰∫ÜÁ≥ªÁªüÊÄßÊ°ÜÊû∂ÔºåÂÆÉÁöÑÊ†∏ÂøÉË¥°ÁåÆÂú®‰∫éÔºö ÊèêÂá∫‰∫ÜÂàÜÂ∏ÉÂºèÂçè‰ΩúÁΩëÁªúÁöÑÂøÖË¶ÅÊÄßÔºåÂπ∂ÈÄöËøáÊ†áÂáÜÂåñÂçèËÆÆÔºàÂ¶ÇA2AÔºâÂÆûÁé∞ ‚Ä¶ ÁõÆÂâçFoundation ModelÊàñËÄÖÊòØÂ§ßÊ®°ÂûãÔºåÁâπÂà´Âú∞ÁÅ´ÔºåÊé•‰∏ãÊù•‰ªãÁªç‰ªÄ‰πàÊòØÂ§ßÊ®°ÂûãÔºåÂ§ßÊ®°ÂûãÁöÑÂü∫Êú¨Ê¶ÇÂøµÔºõÊé•ÁùÄÁúãÁúãÂ§ßÊ®°ÂûãÁöÑÂÆûÈôÖ‰ΩúÁî®ÔºåÁÑ∂ÂêéÂü∫‰∫éËøô‰∫õÂÆûÈôÖ‰ΩúÁî®ÔºåÊàë‰ª¨ÁÆÄÂçïÂ±ïÂºÄÂá†‰∏™Â∫îÁî®Âú∫ÊôØ„ÄÇÊúÄÂêéÂ∞± ‚Ä¶ Foundation ModelsÊ°ÜÊû∂ÂàôËß£ÂÜ≥‰∫ÜAPIÊàêÊú¨Ëøô‰∏™ÈóÆÈ¢òÔºåiOSÂºÄÂèëËÄÖÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®Apple IntelligenceÊèê‰æõÁöÑ30‰∫øÂèÇÊï∞ËßÑÊ®°Á´Ø‰æßÊ®°ÂûãÔºåÊù•‰∏∫Ëá™ÂÆ∂ÁöÑAppÊèê‰æõAIËÉΩÂäõ„ÄÇ Áî±‰∫éÊ®°ÂûãÊòØÁî±ËãπÊûúÊèê‰æõ„ÄÅÁÆóÂäõÂàô ‚Ä¶ ITIL 4 FoundationËÆ§ËØÅÂê´ÈáëÈáèËøòÊòØÈùûÂ∏∏È´òÁöÑÔºå‰∏çÁÆ°ÊòØÂØπËá™Â∑±Êú™Êù•ÂçáËÅåÂä†Ëñ™ËøòÊòØË∑≥ÊßΩÈÉΩÂ∞ÜÊòØ‰∏Ä‰∏™ÈùûÂ∏∏‰∏çÈîôÁöÑÈÄâÊã©ÔºÅ ÈùíËìùÂí®ËØ¢ITÂú®ËøôÊñπÈù¢ÊúâÁùÄË∂ÖÁ∫ß‰∏∞ÂØåÁöÑÁªèÈ™åÔºåÂÖ≥Ê≥®ÔºöÊ∑±Âú≥ÈùíËìùÔºå‰∫ÜËß£Êõ¥Â§öÔºÅ', name='duckduckgo_search', id='e8fb0a04-2f41-48cf-9158-0eac92f16ed4', tool_call_id='call_ZZ4JLC66EkLSvwP1T6vu7CA8'), ToolMessage(content='However, multimodal AI has emerged due to these models ‚Äô fundamental limitations, specifically their lack of context and recognizing nuance. ... AI expert Brien Posey weighed in with his views on the top AI trends going into 2025 , seeing the transformative technology getting a huge boost from ... This year, we witnessed advancements in multimodal AI being applied to tasks like video captioning, sentiment analysis from audio recordings, and ... One of the most promising advancements in AI is the rise of multimodal models . ... Multimodal models are unlocking new applications, agentic AI is ... With recent advancements in multimodal models , AI systems can perform complex tasks involving the simultaneous integration and interpretation of ...', name='duckduckgo_search', id='5bad40f2-ee43-4e75-baac-c2eadd2dbe8f', tool_call_id='call_ifJNVnU3DYStWwNX9QZe5L3C'), ToolMessage(content='The only other AI alignment research agenda I can think of that seems to follow a similar strategy is Shard Theory though it seems more high-level ... ... AI capability development when doing so is necessary for maintaining ... Safety progress : our ability to develop new levels of AI capability safely. ... can substantiate ‚Äòinability‚Äô safety cases, which assert that models cannot, for example, aid biological weapons development ( RAND, 2024 ... Alignment Research Engineer Accelerator ‚Äî AI Safety Technical Program ( 2025 ) ... Alignment Research Engineer Accelerator ‚Äî AI Safety Technical ... This is required both to help researchers develop safer systems and to validate the safety of newly developed systems before they are deployed.', name='duckduckgo_search', id='90170812-e53b-4d21-884d-230194e78be2', tool_call_id='call_LHbfryND7uQqSiwMOqfXUutC'), AIMessage(content='Here‚Äôs a concise, up-to-date summary of the biggest recent advances and active directions in AI research (high-level trends and why they matter).\\n\\nMajor technical advances\\n- Foundation / large-scale pretrained models\\n  - Continued progress in very large pretrained models (text, vision, code) that serve as general-purpose backbones. Improvements focus on better pretraining data, instruction tuning, and safer behavior via human feedback.\\n- Multimodal models\\n  - Models that jointly understand/generate text, images, audio and video are much stronger and more widely used (e.g., image+text + video understanding, cross-modal retrieval, captioning, multimodal generation). This enables modalities to be combined for richer tasks and interfaces.\\n- Agentic systems and tool use\\n  - ‚ÄúAgents‚Äù that plan, call tools (APIs, search, code execution), and decompose problems are now practical. Research covers orchestration, memory, planning, and evaluation of autonomous multi-step behaviors.\\n- Retrieval-augmented and grounded generation\\n  - RAG (retrieval-augmented generation), tools that ground model outputs to external knowledge bases and memory, dramatically improve factuality and up-to-dateness.\\n- Reasoning and compositionality improvements\\n  - Methods like chain-of-thought, tree-of-thought style prompting, self-consistency, and structured reasoning pipelines improve complex multi-step reasoning and planning.\\n- Efficiency, compression, and sparsity\\n  - Techniques such as quantization (4-bit/3-bit training/inference), LoRA/PEFT, distillation, and Mixture-of-Experts (sparse models) reduce compute and cost while retaining performance, enabling on-device or cheaper inference.\\n- Generative models for media (image, audio, video, 3D)\\n  - Diffusion and transformer-based generators continue to scale: higher-fidelity image synthesis, controllable text-to-video, text-to-3D and better audio/music generation are rapidly maturing.\\n- Mechanistic interpretability & robustness work\\n  - Growing body of research peels apart what networks learn (circuits, activation analysis) and develops defenses against adversarial examples and spurious behavior.\\n- Safety, alignment, and evaluation\\n  - New methods and benchmarks for alignment, red-teaming, formal/verifiable safety cases, model editing, and provenance/watermarking. Investment in evaluation suites and auditing pipelines is increasing.\\n- Biomedical and scientific applications\\n  - Specialized foundation models are being applied to protein folding, molecular design, and literature mining‚Äîaccelerating drug discovery and scientific workflows but also raising dual-use concerns.\\n\\nSystems, tooling, and infrastructure\\n- Training & inference optimizations\\n  - Advances like FlashAttention, system-level optimizations, distributed training frameworks (DeepSpeed/Alpa/etc.) and better memory management make large-model training and serving faster and cheaper.\\n- On-device and edge LLMs\\n  - Quantized, distilled, and compact models that run on phones and edge devices are enabling privacy-preserving and low-latency applications.\\n- Better benchmarks and transparency\\n  - Richer, adversarial benchmarks (big-bench, HELM variants) and increased emphasis on model cards, datasheets, and reporting to improve transparency.\\n\\nResearch problems and open challenges\\n- Long-horizon reasoning and generalization remain imperfect.\\n- Robustness to distribution shift, adversarial inputs, and deceptive optimization is an open problem.\\n- Scalable, verifiable alignment methods: there is no agreed, practical recipe yet for provably safe deployment of very capable systems.\\n- Data quality, dataset curation, and biases continue to limit real-world reliability.\\n\\nPolicy, governance, and community trends\\n- More public policy activity (national strategies, EU AI Act style rules, standards work).\\n- Greater investment in safety research, red-teaming, and independent audits.\\n- Rapid open-source ecosystem growth (new open models, toolkits, community benchmarks).\\n\\nWhere to follow updates\\n- ArXiv (cs.LG, cs.AI, stat.ML), Papers with Code, conference proceedings (NeurIPS, ICML, ICLR, CVPR, ACL), and major AI lab blogs (OpenAI, DeepMind, Google Research, Meta AI, etc.). Hugging Face and AI Index are also good aggregators.\\n\\nIf you want, I can:\\n- Summarize the latest papers in a specific subarea (multimodal, agents, interpretability, safety).\\n- Point to a short reading list or recent survey papers.\\n- Give examples of practical applications and toolchains for deploying these advances. Which would you prefer?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 2025, 'prompt_tokens': 2128, 'total_tokens': 4153, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1088, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CeKfyMRiWM8UkONycWiIArocuX4qc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--48445c81-e952-4564-a0ba-10bb87eb3b3b-0', usage_metadata={'input_tokens': 2128, 'output_tokens': 2025, 'total_tokens': 4153, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1088}})]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "queries = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"Who wrote 'To Kill a Mockingbird'?\",\n",
    "    \"Explain the theory of relativity.\",\n",
    "    \"What are the benefits of functional programming?\",\n",
    "    \"How does a blockchain work?\",\n",
    "    \"Can you summarize the plot of '1984' by George Orwell?\",\n",
    "    \"What are the implications of quantum computing?\",\n",
    "]\n",
    "\n",
    "# First few queries use basic_model\n",
    "for i in range(7):\n",
    "    query = queries[i]\n",
    "    result = agent.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "    }, config={\"configurable\": {\"session_id\": \"1234\"}})\n",
    "    print(f\"Query {i}: {result}\")\n",
    "\n",
    "# After 5+ messages, advanced_model kicks in\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What are the latest advancements in AI research?\"}]\n",
    "}, config={\"configurable\": {\"session_id\": \"1234\"}})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the latest advancements in AI research?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  duckduckgo_search (call_hasNXq5VVFPM1Sh7Iwzx0XhR)\n",
      " Call ID: call_hasNXq5VVFPM1Sh7Iwzx0XhR\n",
      "  Args:\n",
      "    query: latest advancements in AI research 2024 2025\n",
      "  duckduckgo_search (call_ZZ4JLC66EkLSvwP1T6vu7CA8)\n",
      " Call ID: call_ZZ4JLC66EkLSvwP1T6vu7CA8\n",
      "  Args:\n",
      "    query: foundation models trends 2024 2025\n",
      "  duckduckgo_search (call_ifJNVnU3DYStWwNX9QZe5L3C)\n",
      " Call ID: call_ifJNVnU3DYStWwNX9QZe5L3C\n",
      "  Args:\n",
      "    query: multimodal AI models 2024 2025 advancements\n",
      "  duckduckgo_search (call_LHbfryND7uQqSiwMOqfXUutC)\n",
      " Call ID: call_LHbfryND7uQqSiwMOqfXUutC\n",
      "  Args:\n",
      "    query: AI safety alignment 2024 2025 developments\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: duckduckgo_search\n",
      "\n",
      "Get the latest news, advances in research , policy work, and education program updates from HAI in your inbox weekly.New this Year: The Official Chinese Version of the 2025 AI Index Report. The state of AI in 2025 : Agents, innovation, and transformation. November 5, 2025 | Survey. Almost all survey respondents say their organizations are using AI , and many have begun to use AI agents. The 2024 MAD (Machine Learning, AI , & Data) landscape showcases a significant expansion, featuring 2,011 logos, an increase from 1,416 the previous year. This growth includes 578 newcomers, a stark contrast to the initial 2012 version, which featured only 139 logos. In January 2025 , China-based AI startup DeepSeek (Ê∑±Â∫¶Ê±ÇÁ¥¢) released DeepSeek-R1, a high-quality large language model (LLM) that allegedly cost much less to develop and operate than Western competitors‚Äô alternatives. Today, we‚Äôre sharing the latest updates to Gemini, your AI assistant, including Deep Research ‚Äî our new agentic feature in Gemini Advanced ‚Äî and access to try Gemini 2.0 Flash, our latest experimental model.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: duckduckgo_search\n",
      "\n",
      "‰ΩÜÊòØËøôÁßçËøΩÊ†πÊ∫ØÊ∫êÂØπÊâæÂá∫foundationÂíåfundamentÁöÑÂå∫Âà´Âπ∂Ê≤°Êúâ‰ªÄ‰πàÂÆûÈôÖ‰∏äÁöÑÂ∏ÆÂä©„ÄÇ ‚ÄúÂéÜÂè≤XX‰∏çÂÖ∑ÊúâÁé∞ÂÆûÊÑè‰πâ‚ÄùÔºåÊîæÂú®foundationÂíåfundament‰∏äÂÜçÂêàÈÄÇ‰∏çËøá‰∫Ü„ÄÇ Áé∞Âú®‰Ω†ÊâæÂá∫ÂçÅ‰∏™Â∏¶ÊúâfoundationÁöÑ ‚Ä¶ „ÄäAdvances and Challenges in Foundation Agents„Äã‰∏∫Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂ∫îÁî®Êèê‰æõ‰∫ÜÁ≥ªÁªüÊÄßÊ°ÜÊû∂ÔºåÂÆÉÁöÑÊ†∏ÂøÉË¥°ÁåÆÂú®‰∫éÔºö ÊèêÂá∫‰∫ÜÂàÜÂ∏ÉÂºèÂçè‰ΩúÁΩëÁªúÁöÑÂøÖË¶ÅÊÄßÔºåÂπ∂ÈÄöËøáÊ†áÂáÜÂåñÂçèËÆÆÔºàÂ¶ÇA2AÔºâÂÆûÁé∞ ‚Ä¶ ÁõÆÂâçFoundation ModelÊàñËÄÖÊòØÂ§ßÊ®°ÂûãÔºåÁâπÂà´Âú∞ÁÅ´ÔºåÊé•‰∏ãÊù•‰ªãÁªç‰ªÄ‰πàÊòØÂ§ßÊ®°ÂûãÔºåÂ§ßÊ®°ÂûãÁöÑÂü∫Êú¨Ê¶ÇÂøµÔºõÊé•ÁùÄÁúãÁúãÂ§ßÊ®°ÂûãÁöÑÂÆûÈôÖ‰ΩúÁî®ÔºåÁÑ∂ÂêéÂü∫‰∫éËøô‰∫õÂÆûÈôÖ‰ΩúÁî®ÔºåÊàë‰ª¨ÁÆÄÂçïÂ±ïÂºÄÂá†‰∏™Â∫îÁî®Âú∫ÊôØ„ÄÇÊúÄÂêéÂ∞± ‚Ä¶ Foundation ModelsÊ°ÜÊû∂ÂàôËß£ÂÜ≥‰∫ÜAPIÊàêÊú¨Ëøô‰∏™ÈóÆÈ¢òÔºåiOSÂºÄÂèëËÄÖÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®Apple IntelligenceÊèê‰æõÁöÑ30‰∫øÂèÇÊï∞ËßÑÊ®°Á´Ø‰æßÊ®°ÂûãÔºåÊù•‰∏∫Ëá™ÂÆ∂ÁöÑAppÊèê‰æõAIËÉΩÂäõ„ÄÇ Áî±‰∫éÊ®°ÂûãÊòØÁî±ËãπÊûúÊèê‰æõ„ÄÅÁÆóÂäõÂàô ‚Ä¶ ITIL 4 FoundationËÆ§ËØÅÂê´ÈáëÈáèËøòÊòØÈùûÂ∏∏È´òÁöÑÔºå‰∏çÁÆ°ÊòØÂØπËá™Â∑±Êú™Êù•ÂçáËÅåÂä†Ëñ™ËøòÊòØË∑≥ÊßΩÈÉΩÂ∞ÜÊòØ‰∏Ä‰∏™ÈùûÂ∏∏‰∏çÈîôÁöÑÈÄâÊã©ÔºÅ ÈùíËìùÂí®ËØ¢ITÂú®ËøôÊñπÈù¢ÊúâÁùÄË∂ÖÁ∫ß‰∏∞ÂØåÁöÑÁªèÈ™åÔºåÂÖ≥Ê≥®ÔºöÊ∑±Âú≥ÈùíËìùÔºå‰∫ÜËß£Êõ¥Â§öÔºÅ\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: duckduckgo_search\n",
      "\n",
      "However, multimodal AI has emerged due to these models ‚Äô fundamental limitations, specifically their lack of context and recognizing nuance. ... AI expert Brien Posey weighed in with his views on the top AI trends going into 2025 , seeing the transformative technology getting a huge boost from ... This year, we witnessed advancements in multimodal AI being applied to tasks like video captioning, sentiment analysis from audio recordings, and ... One of the most promising advancements in AI is the rise of multimodal models . ... Multimodal models are unlocking new applications, agentic AI is ... With recent advancements in multimodal models , AI systems can perform complex tasks involving the simultaneous integration and interpretation of ...\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: duckduckgo_search\n",
      "\n",
      "The only other AI alignment research agenda I can think of that seems to follow a similar strategy is Shard Theory though it seems more high-level ... ... AI capability development when doing so is necessary for maintaining ... Safety progress : our ability to develop new levels of AI capability safely. ... can substantiate ‚Äòinability‚Äô safety cases, which assert that models cannot, for example, aid biological weapons development ( RAND, 2024 ... Alignment Research Engineer Accelerator ‚Äî AI Safety Technical Program ( 2025 ) ... Alignment Research Engineer Accelerator ‚Äî AI Safety Technical ... This is required both to help researchers develop safer systems and to validate the safety of newly developed systems before they are deployed.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here‚Äôs a concise, up-to-date summary of the biggest recent advances and active directions in AI research (high-level trends and why they matter).\n",
      "\n",
      "Major technical advances\n",
      "- Foundation / large-scale pretrained models\n",
      "  - Continued progress in very large pretrained models (text, vision, code) that serve as general-purpose backbones. Improvements focus on better pretraining data, instruction tuning, and safer behavior via human feedback.\n",
      "- Multimodal models\n",
      "  - Models that jointly understand/generate text, images, audio and video are much stronger and more widely used (e.g., image+text + video understanding, cross-modal retrieval, captioning, multimodal generation). This enables modalities to be combined for richer tasks and interfaces.\n",
      "- Agentic systems and tool use\n",
      "  - ‚ÄúAgents‚Äù that plan, call tools (APIs, search, code execution), and decompose problems are now practical. Research covers orchestration, memory, planning, and evaluation of autonomous multi-step behaviors.\n",
      "- Retrieval-augmented and grounded generation\n",
      "  - RAG (retrieval-augmented generation), tools that ground model outputs to external knowledge bases and memory, dramatically improve factuality and up-to-dateness.\n",
      "- Reasoning and compositionality improvements\n",
      "  - Methods like chain-of-thought, tree-of-thought style prompting, self-consistency, and structured reasoning pipelines improve complex multi-step reasoning and planning.\n",
      "- Efficiency, compression, and sparsity\n",
      "  - Techniques such as quantization (4-bit/3-bit training/inference), LoRA/PEFT, distillation, and Mixture-of-Experts (sparse models) reduce compute and cost while retaining performance, enabling on-device or cheaper inference.\n",
      "- Generative models for media (image, audio, video, 3D)\n",
      "  - Diffusion and transformer-based generators continue to scale: higher-fidelity image synthesis, controllable text-to-video, text-to-3D and better audio/music generation are rapidly maturing.\n",
      "- Mechanistic interpretability & robustness work\n",
      "  - Growing body of research peels apart what networks learn (circuits, activation analysis) and develops defenses against adversarial examples and spurious behavior.\n",
      "- Safety, alignment, and evaluation\n",
      "  - New methods and benchmarks for alignment, red-teaming, formal/verifiable safety cases, model editing, and provenance/watermarking. Investment in evaluation suites and auditing pipelines is increasing.\n",
      "- Biomedical and scientific applications\n",
      "  - Specialized foundation models are being applied to protein folding, molecular design, and literature mining‚Äîaccelerating drug discovery and scientific workflows but also raising dual-use concerns.\n",
      "\n",
      "Systems, tooling, and infrastructure\n",
      "- Training & inference optimizations\n",
      "  - Advances like FlashAttention, system-level optimizations, distributed training frameworks (DeepSpeed/Alpa/etc.) and better memory management make large-model training and serving faster and cheaper.\n",
      "- On-device and edge LLMs\n",
      "  - Quantized, distilled, and compact models that run on phones and edge devices are enabling privacy-preserving and low-latency applications.\n",
      "- Better benchmarks and transparency\n",
      "  - Richer, adversarial benchmarks (big-bench, HELM variants) and increased emphasis on model cards, datasheets, and reporting to improve transparency.\n",
      "\n",
      "Research problems and open challenges\n",
      "- Long-horizon reasoning and generalization remain imperfect.\n",
      "- Robustness to distribution shift, adversarial inputs, and deceptive optimization is an open problem.\n",
      "- Scalable, verifiable alignment methods: there is no agreed, practical recipe yet for provably safe deployment of very capable systems.\n",
      "- Data quality, dataset curation, and biases continue to limit real-world reliability.\n",
      "\n",
      "Policy, governance, and community trends\n",
      "- More public policy activity (national strategies, EU AI Act style rules, standards work).\n",
      "- Greater investment in safety research, red-teaming, and independent audits.\n",
      "- Rapid open-source ecosystem growth (new open models, toolkits, community benchmarks).\n",
      "\n",
      "Where to follow updates\n",
      "- ArXiv (cs.LG, cs.AI, stat.ML), Papers with Code, conference proceedings (NeurIPS, ICML, ICLR, CVPR, ACL), and major AI lab blogs (OpenAI, DeepMind, Google Research, Meta AI, etc.). Hugging Face and AI Index are also good aggregators.\n",
      "\n",
      "If you want, I can:\n",
      "- Summarize the latest papers in a specific subarea (multimodal, agents, interpretability, safety).\n",
      "- Point to a short reading list or recent survey papers.\n",
      "- Give examples of practical applications and toolchains for deploying these advances. Which would you prefer?\n"
     ]
    }
   ],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weather tool Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "weather_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"location\": {\"type\": \"string\"},\n",
    "        \"units\": {\"type\": \"string\"},\n",
    "        \"include_forecast\": {\"type\": \"boolean\"}\n",
    "    },\n",
    "    \"required\": [\"location\", \"units\", \"include_forecast\"]\n",
    "}\n",
    "\n",
    "@tool(args_schema=weather_schema)\n",
    "def get_weather(location: str, units: str = \"celsius\", include_forecast: bool = False) -> str:\n",
    "    \"\"\"Get current weather and optional forecast.\"\"\"\n",
    "    temp = 22 if units == \"celsius\" else 72\n",
    "    result = f\"Current weather in {location}: {temp} degrees {units[0].upper()}\"\n",
    "    if include_forecast:\n",
    "        result += \"\\nNext 5 days: Sunny\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Context\n",
    "\n",
    "[Read first](https://docs.langchain.com/oss/python/langchain/tools#accessing-context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Context:\n",
    "\n",
    "Static runtime context represents immutable data like user metadata, tools, and database connections that are passed to an application at the start of a run via the context argument to invoke. \n",
    "\n",
    "*This data does not change during execution.*\n",
    "\n",
    "[Reference](https://docs.langchain.com/oss/python/concepts/context#static-runtime-context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cCNvU4BidzG-"
   },
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ContextSchema:\n",
    "    user_name: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def personalized_prompt(request: ModelRequest) -> str:  \n",
    "    user_name = request.runtime.context.user_name\n",
    "    \n",
    "    return f\"You are a helpful assistant. Address the user as {user_name}.\"\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5-nano-2025-08-07\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    middleware=[personalized_prompt],\n",
    "    context_schema=ContextSchema\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather like in Wexford?\"}]},\n",
    "    context=ContextSchema(user_name=\"Mo Che\")  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is the weather like in Wexford?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_nlYhSkEA3Hmk0kmCcsNKGdfZ)\n",
      " Call ID: call_nlYhSkEA3Hmk0kmCcsNKGdfZ\n",
      "  Args:\n",
      "    location: Wexford\n",
      "    units: metric\n",
      "    include_forecast: False\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "Current weather in Wexford: 72 degrees M\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_6AVoHuSMtc5w6IuculEMLeJC)\n",
      " Call ID: call_6AVoHuSMtc5w6IuculEMLeJC\n",
      "  Args:\n",
      "    location: Wexford\n",
      "    units: metric\n",
      "    include_forecast: False\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "Current weather in Wexford: 72 degrees M\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_oS9LWZoVpHOSDihSXk7fhVQd)\n",
      " Call ID: call_oS9LWZoVpHOSDihSXk7fhVQd\n",
      "  Args:\n",
      "    location: Wexford\n",
      "    units: imperial\n",
      "    include_forecast: False\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "Current weather in Wexford: 72 degrees I\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (call_J8eeLskxZxzdVpGLlTSMQfJm)\n",
      " Call ID: call_J8eeLskxZxzdVpGLlTSMQfJm\n",
      "  Args:\n",
      "    location: Wexford\n",
      "    units: metric\n",
      "    include_forecast: False\n",
      "  get_weather (call_HS2FAplITBoHHTC7IelEIhv1)\n",
      " Call ID: call_HS2FAplITBoHHTC7IelEIhv1\n",
      "  Args:\n",
      "    location: Wexford\n",
      "    units: imperial\n",
      "    include_forecast: False\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "Current weather in Wexford: 72 degrees M\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weather\n",
      "\n",
      "Current weather in Wexford: 72 degrees I\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Mo Che, current weather in Wexford is about 22¬∞C (roughly 72¬∞F). Want me to fetch a forecast or add details like humidity and wind?\n"
     ]
    }
   ],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using State:\n",
    "\n",
    "Dynamic runtime context represents mutable data that can evolve during a single run and is managed through the LangGraph state object. This includes conversation history, intermediate results, and values derived from tools or LLM outputs. In LangGraph, the state object acts as short-term memory during a run.\n",
    "\n",
    "[Reference](https://docs.langchain.com/oss/python/concepts/context#dynamic-runtime-context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='8ee82e40-6ecd-4dc6-9c16-83a26a83dd23'), AIMessage(content='Hi Mo! Nice to meet you. What would you like help with today? I can answer questions, draft emails, brainstorm ideas, explain concepts, write or debug code, summarize articles, plan projects, or just chat. Tell me your goal or drop a prompt, and I‚Äôll help.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 388, 'prompt_tokens': 24, 'total_tokens': 412, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CeKuRSujozjH5zerrxup1nwDnBJj3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--577de7c4-97b0-4489-806a-86d56ccade2a-0', usage_metadata={'input_tokens': 24, 'output_tokens': 388, 'total_tokens': 412, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}})], 'user_name': 'Mo Che'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langchain.agents import AgentState\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "class CustomState(AgentState):  \n",
    "    user_name: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def personalized_prompt(request: ModelRequest) -> str:  \n",
    "    user_name = request.state.get(\"user_name\", \"User\")\n",
    "    return f\"You are a helpful assistant. User's name is {user_name}\"\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5-nano-2025-08-07\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    state_schema=CustomState,  \n",
    "    middleware=[personalized_prompt],  \n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"hi!\"}],\n",
    "    \"user_name\": \"Mo Che\"\n",
    "}) # type: ignore\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Turning on memory: Memory is a powerful feature that allows you to persist the agent‚Äôs state across multiple invocations. Otherwise, the state is scoped only to a single run. See next notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Dynamic system prompt](https://docs.langchain.com/oss/python/langchain/agents#dynamic-system-prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*See also [Tool Strategy][Tool Strategy]*\n",
    "\n",
    "[Tool Strategy]: https://docs.langchain.com/oss/python/langchain/agents#toolstrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Life-cycle Context](https://docs.langchain.com/oss/python/langchain/context-engineering#life-cycle-context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Create an agent that uses a different LLM model based on whether the user has a paid subscription or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain.agents.middleware import AgentMiddleware\n",
    "from langchain.messages import AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ContextSchema:  \n",
    "    subscription: str = \"free\"  # or \"paid\"\n",
    "\n",
    "# use gpt-5-mini-2025-08-07 for paid users, gpt-5-nano-2025-08-07 for free users\n",
    "\n",
    "free_model = ChatOpenAI(model=\"gpt-5-nano-2025-08-07\")\n",
    "paid_model = ChatOpenAI(model=\"gpt-5-mini-2025-08-07\")\n",
    "\n",
    "@dynamic_prompt\n",
    "def personalized_prompt(request: ModelRequest) -> str:      \n",
    "    return f\"You are a helpful assistant. Thank the user for being a {request.runtime.context.subscription} subscriber.\"\n",
    "\n",
    "\n",
    "class DynamicModelMiddleware(AgentMiddleware):\n",
    "\n",
    "    def wrap_model_call(self, request, handler):\n",
    "        self.subscription = request.runtime.context.subscription\n",
    "        if self.subscription == \"paid\":\n",
    "            request.model = ChatOpenAI(model=\"gpt-5-mini-2025-08-07\")\n",
    "        else:\n",
    "            request.model = ChatOpenAI(model=\"gpt-5-nano-2025-08-07\")\n",
    "\n",
    "        return handler(request)\n",
    "\n",
    "    def __init__(self: str) -> None:\n",
    "        self.subscription = 'free'\n",
    "\n",
    "agent = create_agent(\n",
    "    model=free_model,\n",
    "    middleware=[DynamicModelMiddleware(), personalized_prompt],\n",
    "    context_schema=ContextSchema\n",
    ")\n",
    "\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the meaning of life?\"}]},\n",
    "    context=ContextSchema(subscription=\"paid\")  \n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What AI model are you using? Provide the exact tag.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thanks for being a paid subscriber ‚Äî I appreciate it.\n",
      "\n",
      "I don‚Äôt have access to runtime metadata in this chat, so I can‚Äôt read or report the exact model tag being used here. If you need the exact tag, here are ways to get it:\n",
      "\n",
      "- If you‚Äôre calling the OpenAI API yourself: check the model parameter you passed in your request or the response JSON (there‚Äôs a \"model\" field in many responses). Example (pseudo-JSON):\n",
      "  {\n",
      "    \"id\": \"...\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"model\": \"gpt-4o-mini\",\n",
      "    ...\n",
      "  }\n",
      "\n",
      "- If you‚Äôre using the ChatGPT web or app: check the model selector in the UI (top of the chat or settings) or your plan details, or contact platform support for the runtime tag.\n",
      "\n",
      "If you share how you‚Äôre accessing the service (API, web app, other), I can give more specific steps to find the exact tag.\n"
     ]
    }
   ],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    msg.pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaeOuS9ve0rq"
   },
   "source": [
    "# üîÑ **Agents and Memory**\n",
    "\n",
    "### **Stateless Agent Characteristics**\n",
    "\n",
    "- **Current Limitation**: Inability to recall past interactions by default.\n",
    "\n",
    "### **Enabling Memory**:\n",
    "\n",
    "- **Method**: Integrate previous chat history into the agent.\n",
    "\n",
    "- **Key Requirement**: The chat history variable must be named \"chat_history\" for compatibility with the current prompt.\n",
    "\n",
    "- **Flexibility**: Altering the prompt\n",
    "allows for different variable naming.\n",
    "\n",
    "üîë **Takeaway**: Adjusting the prompt or incorporating chat history enables stateful interactions, enhancing the agent's capability to remember and utilize past interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "giW5n60Te07e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather like in Wexford?', additional_kwargs={}, response_metadata={}, id='0bebb529-4ac9-4c28-af50-f0b718f8f954'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 485, 'prompt_tokens': 145, 'total_tokens': 630, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchEmQRBdoLIAAZ6egR1QJH64fAr2', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--b5afa9ec-c9cb-4374-9232-fb0aac956bf6-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'metric', 'include_forecast': False}, 'id': 'call_YmnjJOtHl2e8VxKuwv5a3KeW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 145, 'output_tokens': 485, 'total_tokens': 630, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees M', name='get_weather', id='9fe2426b-896e-40f0-aba8-ac99c5aee6bc', tool_call_id='call_YmnjJOtHl2e8VxKuwv5a3KeW'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 485, 'prompt_tokens': 200, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchEqCnUOBtgAtltLoXye5GJ2ctt5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f0c250d7-24be-49b0-b91d-9a38932f5ae7-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'metric', 'include_forecast': False}, 'id': 'call_WP0STYcZ1LnOIB2HU09R2Z3r', 'type': 'tool_call'}], usage_metadata={'input_tokens': 200, 'output_tokens': 485, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees M', name='get_weather', id='4119436a-f951-41ed-b20d-b42529f10ca0', tool_call_id='call_WP0STYcZ1LnOIB2HU09R2Z3r'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 549, 'prompt_tokens': 255, 'total_tokens': 804, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchEv5Ktwf9JYh4VjlpkkFDTx6QRm', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--a3dac125-399b-4494-afc1-5e589474de0b-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'metric', 'include_forecast': False}, 'id': 'call_rBpr1hJnHEmpNFawY7cMOIvP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 255, 'output_tokens': 549, 'total_tokens': 804, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees M', name='get_weather', id='24204520-be03-4aae-bfc1-8ae75c816f05', tool_call_id='call_rBpr1hJnHEmpNFawY7cMOIvP'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 614, 'prompt_tokens': 310, 'total_tokens': 924, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchF2i3bBVg48aIvMNF3G4mKHuNz6', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--3b5a4cf9-5954-4ccc-be43-8c3d30a86690-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'imperial', 'include_forecast': False}, 'id': 'call_NZTk3u8gZq5k89RQALg3H5Q2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 310, 'output_tokens': 614, 'total_tokens': 924, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 576}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees I', name='get_weather', id='87bdc7c3-2d68-4d30-aebf-96d419a1aa8f', tool_call_id='call_NZTk3u8gZq5k89RQALg3H5Q2'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 594, 'prompt_tokens': 366, 'total_tokens': 960, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchF7AY21Eq7o0dtWLCvEiyIA48R6', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--05fefa24-99e1-4b45-8833-61ee741de460-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'metric', 'include_forecast': False}, 'id': 'call_OGvu6BEmYBBz7zaDOXQ5IHoU', 'type': 'tool_call'}, {'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'imperial', 'include_forecast': False}, 'id': 'call_gsKyKPyJStubwKWToTvP2YWs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 366, 'output_tokens': 594, 'total_tokens': 960, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees M', name='get_weather', id='71c3e257-3770-41eb-8239-c7b5d0b7accc', tool_call_id='call_OGvu6BEmYBBz7zaDOXQ5IHoU'),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees I', name='get_weather', id='3715ce37-1416-4aa5-b0d1-d5aa930ca38f', tool_call_id='call_gsKyKPyJStubwKWToTvP2YWs'),\n",
       "  AIMessage(content='I‚Äôm seeing conflicting unit tags in the current reading for Wexford. It shows 72 degrees, but the unit label isn‚Äôt clear (M vs I).\\n\\nWould you like the current temperature in:\\n- Celsius (¬∞C) or\\n- Fahrenheit (¬∞F)?\\n\\nI can fetch a fresh reading in your preferred unit and, if you want, a short forecast afterward.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1173, 'prompt_tokens': 485, 'total_tokens': 1658, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1088, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchFBDzn2XIS9PiCSFwY3KXZbobJT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d9a3d545-0077-467f-bc3c-587a6debbda4-0', usage_metadata={'input_tokens': 485, 'output_tokens': 1173, 'total_tokens': 1658, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1088}})]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type: ignore\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI \n",
    "from langgraph.checkpoint.memory import InMemorySaver  \n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5-nano-2025-08-07\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    "    checkpointer=InMemorySaver()\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather like in Wexford?\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is the weather like in Wexford?', additional_kwargs={}, response_metadata={}, id='0bebb529-4ac9-4c28-af50-f0b718f8f954'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 485, 'prompt_tokens': 145, 'total_tokens': 630, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchEmQRBdoLIAAZ6egR1QJH64fAr2', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--b5afa9ec-c9cb-4374-9232-fb0aac956bf6-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'metric', 'include_forecast': False}, 'id': 'call_YmnjJOtHl2e8VxKuwv5a3KeW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 145, 'output_tokens': 485, 'total_tokens': 630, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees M', name='get_weather', id='9fe2426b-896e-40f0-aba8-ac99c5aee6bc', tool_call_id='call_YmnjJOtHl2e8VxKuwv5a3KeW'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 485, 'prompt_tokens': 200, 'total_tokens': 685, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchEqCnUOBtgAtltLoXye5GJ2ctt5', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--f0c250d7-24be-49b0-b91d-9a38932f5ae7-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'metric', 'include_forecast': False}, 'id': 'call_WP0STYcZ1LnOIB2HU09R2Z3r', 'type': 'tool_call'}], usage_metadata={'input_tokens': 200, 'output_tokens': 485, 'total_tokens': 685, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees M', name='get_weather', id='4119436a-f951-41ed-b20d-b42529f10ca0', tool_call_id='call_WP0STYcZ1LnOIB2HU09R2Z3r'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 549, 'prompt_tokens': 255, 'total_tokens': 804, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchEv5Ktwf9JYh4VjlpkkFDTx6QRm', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--a3dac125-399b-4494-afc1-5e589474de0b-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'metric', 'include_forecast': False}, 'id': 'call_rBpr1hJnHEmpNFawY7cMOIvP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 255, 'output_tokens': 549, 'total_tokens': 804, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees M', name='get_weather', id='24204520-be03-4aae-bfc1-8ae75c816f05', tool_call_id='call_rBpr1hJnHEmpNFawY7cMOIvP'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 614, 'prompt_tokens': 310, 'total_tokens': 924, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 576, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchF2i3bBVg48aIvMNF3G4mKHuNz6', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--3b5a4cf9-5954-4ccc-be43-8c3d30a86690-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'imperial', 'include_forecast': False}, 'id': 'call_NZTk3u8gZq5k89RQALg3H5Q2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 310, 'output_tokens': 614, 'total_tokens': 924, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 576}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees I', name='get_weather', id='87bdc7c3-2d68-4d30-aebf-96d419a1aa8f', tool_call_id='call_NZTk3u8gZq5k89RQALg3H5Q2'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 594, 'prompt_tokens': 366, 'total_tokens': 960, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 512, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchF7AY21Eq7o0dtWLCvEiyIA48R6', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--05fefa24-99e1-4b45-8833-61ee741de460-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'metric', 'include_forecast': False}, 'id': 'call_OGvu6BEmYBBz7zaDOXQ5IHoU', 'type': 'tool_call'}, {'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'imperial', 'include_forecast': False}, 'id': 'call_gsKyKPyJStubwKWToTvP2YWs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 366, 'output_tokens': 594, 'total_tokens': 960, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 512}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees M', name='get_weather', id='71c3e257-3770-41eb-8239-c7b5d0b7accc', tool_call_id='call_OGvu6BEmYBBz7zaDOXQ5IHoU'),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees I', name='get_weather', id='3715ce37-1416-4aa5-b0d1-d5aa930ca38f', tool_call_id='call_gsKyKPyJStubwKWToTvP2YWs'),\n",
       "  AIMessage(content='I‚Äôm seeing conflicting unit tags in the current reading for Wexford. It shows 72 degrees, but the unit label isn‚Äôt clear (M vs I).\\n\\nWould you like the current temperature in:\\n- Celsius (¬∞C) or\\n- Fahrenheit (¬∞F)?\\n\\nI can fetch a fresh reading in your preferred unit and, if you want, a short forecast afterward.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1173, 'prompt_tokens': 485, 'total_tokens': 1658, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1088, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchFBDzn2XIS9PiCSFwY3KXZbobJT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--d9a3d545-0077-467f-bc3c-587a6debbda4-0', usage_metadata={'input_tokens': 485, 'output_tokens': 1173, 'total_tokens': 1658, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1088}}),\n",
       "  HumanMessage(content='in celsius please', additional_kwargs={}, response_metadata={}, id='f2f2156b-8ab2-4239-b18a-a82b4e6f3c21'),\n",
       "  AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 677, 'prompt_tokens': 575, 'total_tokens': 1252, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 640, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchHtXJSstOXUCw2rqD0qxR5lcvrh', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--ea4601b1-2cb0-45c2-ae9e-fb4a591c7105-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Wexford, Ireland', 'units': 'metric', 'include_forecast': False}, 'id': 'call_SxC07I6EewSGPMLzT5OMlxKz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 575, 'output_tokens': 677, 'total_tokens': 1252, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 640}}),\n",
       "  ToolMessage(content='Current weather in Wexford, Ireland: 72 degrees M', name='get_weather', id='c181362a-b3e5-47a0-a7db-548bc5c0df44', tool_call_id='call_SxC07I6EewSGPMLzT5OMlxKz'),\n",
       "  AIMessage(content='Approximately 22¬∞C (based on the latest 72¬∞F reading converted to Celsius). \\n\\nNote: the metric feed is showing 72 with an unclear unit label, which seems like a data hiccup. I can fetch a fresh, clearly labeled Celsius value and, if you‚Äôd like, a short forecast.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1799, 'prompt_tokens': 630, 'total_tokens': 2429, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1728, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CchHyp3rTWoaLKUvG85zGI1bMuPDq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--948c3114-f0a8-489f-a2a0-fb05d673acba-0', usage_metadata={'input_tokens': 630, 'output_tokens': 1799, 'total_tokens': 2429, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1728}})]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"in celsius please\"}]},\n",
    "    config={\"configurable\": {\"thread_id\": \"1\"}} # try without thread_id\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Config\n",
    "\n",
    "The `thread_id` in config is used by:\n",
    "\n",
    "`InMemorySaver` to retrieve the correct chat history for that session\n",
    "Middleware functions to track conversation context (like your `dynamic_model_selection` function)\n",
    "\n",
    "**Without config**:\n",
    "Each invoke call is stateless and independent, and memory/history features won't work.\n",
    "\n",
    "**With config**:\n",
    "Multiple invoke calls with the same session_id can share state and maintain conversation history across calls."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNwun/3i5Xut+SHj9vKI4il",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
