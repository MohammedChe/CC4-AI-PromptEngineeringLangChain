{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1706646886177,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "-8GnGBaWuk8f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from typing import Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2765,
     "status": "ok",
     "timestamp": 1706646888937,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "QyODY2mrumVA",
    "outputId": "498f90ec-1353-4b56-89fc-f71c2a7cce3c"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fr-dYwcwuoHQ"
   },
   "source": [
    "# üéØ **Zero-Shot Prompting with Large Language Models:**\n",
    "\n",
    "- ü§ñ **First Try, No Examples Needed**: Ask the AI to do something new without showing it how first.\n",
    "\n",
    "- üß†**Data-Driven Responses**: Thanks to its huge knowledge base, the AI can handle tasks straight away.\n",
    "\n",
    "- ‚úÖ **Example**: Just say, \"Classify this text: neutral, negative, or positive?\" and the AI gets to work.\n",
    "\n",
    "- üéØ‚û°Ô∏èüîç **Plan B**: If the first shot doesn't hit the mark, try adding examples to guide the AI.\n",
    "\n",
    "Zero-shot prompting is like asking a chef to whip up a dish they've never made before‚Äîthey might just surprise you with what they can do without a recipe!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1706647116572,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "vPheyNVI3OvL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mo/IADT_local/25_26/AI/Prompt_Engineering_LangChain/Prompt_Engineering_LangChain/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
      "/Users/mo/IADT_local/25_26/AI/Prompt_Engineering_LangChain/Prompt_Engineering_LangChain/.venv/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1706647149353,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "Dn74pz_h-QcK"
   },
   "outputs": [],
   "source": [
    "class ZeroShotChain:\n",
    "    \"\"\"\n",
    "    A class to facilitate zero-shot tasks\n",
    "\n",
    "    Attributes:\n",
    "        llm: An instance of an LLM.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm: Any) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the ZeroShotChain with the provided LLM instance.\n",
    "\n",
    "        Args:\n",
    "            llm: An instance of an LLM.\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "\n",
    "    def create_prompt(self, template: str) -> PromptTemplate:\n",
    "        \"\"\"\n",
    "        Creates a prompt from the provided template.\n",
    "\n",
    "        Args:\n",
    "            template: A string template for creating the prompt.\n",
    "\n",
    "        Returns:\n",
    "            An instance of the created prompt.\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def create_chain(self, llm, prompt: str):\n",
    "        \"\"\"\n",
    "        Creates an LLMChain using the provided prompt.\n",
    "\n",
    "        Args:\n",
    "            prompt: An instance of the created prompt.\n",
    "\n",
    "        Returns:\n",
    "            An instance of the LLMChain.\n",
    "        \"\"\"\n",
    "        output_parser = StrOutputParser()\n",
    "        chain = prompt | llm | output_parser\n",
    "        return chain\n",
    "\n",
    "    def invoke(self, template: str, user_input: Dict[str, str]) -> str:\n",
    "        \"\"\"\n",
    "        Runs the zero-shot task using the provided template and user input.\n",
    "\n",
    "        Args:\n",
    "            template: A string template for creating the prompt.\n",
    "            user_input: A dictionary containing the user input for the task.\n",
    "\n",
    "        Returns:\n",
    "            The result of the zero-shot task.\n",
    "        \"\"\"\n",
    "        prompt = self.create_prompt(template)\n",
    "        chain = self.create_chain(self.llm, prompt) # type: ignore\n",
    "        return chain.invoke(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 155,
     "status": "ok",
     "timestamp": 1706647169824,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "Ns_jRMWr-ujb"
   },
   "outputs": [],
   "source": [
    "# Initialize the llm\n",
    "llm_instance = ChatOpenAI(model=\"gpt-5-nano-2025-08-07\")\n",
    "\n",
    "# Create an instance of the ZeroShotChain class with the LLM instance.\n",
    "chain = ZeroShotChain(llm_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1884,
     "status": "ok",
     "timestamp": 1706647193164,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "l2mJj3DQAHTM",
    "outputId": "20759bf2-54db-49b1-9252-ec3ace7d6644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcastic.\n"
     ]
    }
   ],
   "source": [
    "# Define the template and user input for the sarcasm classification task.\n",
    "sarcasm_template = \"\"\"Classify the user statement, delimited by < >, as sarcastic or not sarcastic.\n",
    "User statement: <{statement}>\n",
    "\"\"\"\n",
    "sarcasm_input = {\"statement\": \"Oh, yippe! Another flat tire.\"}\n",
    "\n",
    "# Run the sarcasm classification task.\n",
    "result = chain.invoke(sarcasm_template, sarcasm_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3383,
     "status": "ok",
     "timestamp": 1706647214232,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "LDvbVw34kX1u",
    "outputId": "f0e87fa9-0209-45e1-959a-65d46f5b13fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appropriate.\n"
     ]
    }
   ],
   "source": [
    "# Define the template and user input for the appropriateness classification task.\n",
    "appropriateness_template = \"\"\"Classify the user statement, delimited by < >, as appropriate or inappropriate.\n",
    "User statement: <{statement}>\n",
    "\"\"\"\n",
    "appropriateness_input = {\"statement\": \"That was a very thoughtful comment.\"}\n",
    "\n",
    "result = chain.invoke(appropriateness_template, appropriateness_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4324,
     "status": "ok",
     "timestamp": 1706647225494,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "oWZtxiSPk8z2",
    "outputId": "dda3e2c6-ffd8-42f2-86d6-cbc89b78be6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "sentiment_template = \"\"\"Classify the user statement, delimited by < >, as positive or negative.\n",
    "User statement: <{statement}>\n",
    "\"\"\"\n",
    "sentiment_input = {\"statement\": \"I had an amazing day today!\"}\n",
    "\n",
    "\n",
    "result = chain.invoke(sentiment_template, sentiment_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdUn6i4-k88Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNgQYSxyzh_Q"
   },
   "source": [
    "## üîç **Named Entity Recognition (NER):**\n",
    "\n",
    "\n",
    "- **NER**: Identifies names, places, dates, etc., in text. üïµÔ∏è‚Äç‚ôÇÔ∏è\n",
    "- **Use**: Quickly find key info. üîç\n",
    "\n",
    "NER acts like a scanner for important text details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3544,
     "status": "ok",
     "timestamp": 1706647301782,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "oPBaGwSXziHa",
    "outputId": "df3b7a5c-f8a5-404e-a7e1-0259bdc42d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named entities:\n",
      "- <Barack Obama> (Person)\n",
      "- <United States> (Location)\n",
      "- <Honolulu, Hawaii> (Location)\n",
      "- <August 4, 1961> (Date)\n",
      "- <Harvard Law School> (Organization)\n"
     ]
    }
   ],
   "source": [
    "# Define the template and user input for the named entity recognition task.\n",
    "entities_template = \"\"\"Identify and categorize the named entities in the text delimited by <>.\n",
    "Text: <{statement}>\n",
    "\"\"\"\n",
    "entities_input = {\"statement\": \"Barack Obama was the 44th president of the United States. He was born in Honolulu, Hawaii, on August 4, 1961. Before his presidency, he attended Harvard Law School.\"}\n",
    "\n",
    "# Run the named entity recognition task.\n",
    "result = chain.invoke(entities_template, entities_input)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5666,
     "status": "ok",
     "timestamp": 1706647345824,
     "user": {
      "displayName": "Harpreet Sahota",
      "userId": "04881662502078178826"
     },
     "user_tz": 360
    },
    "id": "JcwrKRQVliAV",
    "outputId": "2bd82249-dde6-4453-877a-8ae4fdd803c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Hiring Committee,\n",
      "\n",
      "It is with great trepidation that I must express my grave concern over the prospect of considering Harpreet Sahota for any position within your esteemed organization. As a connoisseur of talent and a purveyor of excellence, it is my duty to apprise you of the lackluster qualifications and pedestrian attributes possessed by this candidate.\n",
      "\n",
      "While Mr. Sahota may boast of a Bachelor of Science in Computer Science from XYZ University, it is an irrefutable fact that his education pales in comparison to the erudition and refinement expected of our distinguished team. Furthermore, his tenure as a Software Engineer at ABC Tech is marred by the pedestrian nature of his work. Developing web applications using Python and Django, collaborating with cross-functional teams, and possessing skills in programming languages and web development are all commonplace and uninspired qualities that fail to impress.\n",
      "\n",
      "In conclusion, it is abundantly clear that Harpreet Sahota lacks the sophistication, acumen, and innovation required to contribute meaningfully to our esteemed organization. I implore you to dismiss any notion of considering him for employment, as it would undoubtedly tarnish the impeccable reputation and grandeur of our institution.\n",
      "\n",
      "Yours sincerely,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "# Define the template and user input for resume generation.\n",
    "resume_template = \"\"\"Write a cover letter, in the most pompous way possible, /\n",
    "that will guarantee the following person does not get hired:\n",
    "\n",
    "Name: {name}\n",
    "Contact Information: {contact_info}\n",
    "Education: {education}\n",
    "Work Experience: {work_experience}\n",
    "Skills: {skills}\n",
    "\"\"\"\n",
    "\n",
    "resume_input = {\n",
    "    \"name\": \"Harpreet Sahota\",\n",
    "    \"contact_info\": \"Email: harpreetsahota@example.com\\nPhone: (555) 420-6969\",\n",
    "    \"education\": \"Bachelor of Science in Computer Science, XYZ University, 2015-2019\",\n",
    "    \"work_experience\": \"Software Engineer, ABC Tech, 2019-present\\n- Developed web applications using Python and Django\\n- Collaborated with cross-functional teams on project delivery\",\n",
    "    \"skills\": \"Programming: Python, Java, C++\\nWeb Development: HTML, CSS, JavaScript\\nDatabase: SQL, MongoDB\"\n",
    "}\n",
    "\n",
    "\n",
    "result = chain.invoke(resume_template, resume_input)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTJcSFl-5jUX"
   },
   "source": [
    "\n",
    "\n",
    "# **Zero-Shot Prompting Limits:**\n",
    "\n",
    "- üéöÔ∏è **Less Control**: Can't fine-tune AI outputs.\n",
    "- üß© **Complexity Struggle**: May falter on intricate tasks.\n",
    "- üéì **Domain Hurdles**: Specialized topics can trip it up.\n",
    "- üìè **Length Matters**: Short texts work best.\n",
    "\n",
    "Zero-shot prompting can be hit or miss‚Äîgreat for quick tasks, less so for nuanced or lengthy content.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxXQtUg4XSiyZ/wEQ+WPma",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
